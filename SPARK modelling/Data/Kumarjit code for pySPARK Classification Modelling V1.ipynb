{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'findspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ff073c74b5db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mfindspark\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'findspark'"
     ]
    }
   ],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init() # for initialization of SPARK context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.getOrCreate() # if there is any existing session it will not create new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading it from VP IP\n",
    "\n",
    "customer_details = spark.read.csv('hdfs://192.168.232.128:8020/user/cloudera/hackathon/customer_details.csv',header=True)\n",
    "customer_cdr = spark.read.csv('hdfs://192.168.232.128:8020/user/cloudera/hackathon/customer_cdr.csv',header=True)\n",
    "plan_details = spark.read.csv('hdfs://192.168.232.128:8020/user/cloudera/hackathon/plan_details.csv',header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now not pandas but SPARK needs to read the files\n",
    "\n",
    "h_cdr = spark.read.csv(\"C:\\\\Users\\\\inkpathak\\\\Desktop\\\\Hackathon\\\\Data\\\\cdr.csv\", header = True)\n",
    "h_complaint = spark.read.csv(\"C:\\\\Users\\\\inkpathak\\\\Desktop\\\\Hackathon\\\\Data\\\\complaint.csv\", header = True)\n",
    "h_cust_churn = spark.read.csv(\"C:\\\\Users\\\\inkpathak\\\\Desktop\\\\Hackathon\\\\Data\\\\customer_churn_demography.csv\", header = True)\n",
    "h_revenue = spark.read.csv(\"C:\\\\Users\\\\inkpathak\\\\Desktop\\\\Hackathon\\\\Data\\\\revenue.csv\", header = True)\n",
    "h_signal = spark.read.csv(\"C:\\\\Users\\\\inkpathak\\\\Desktop\\\\Hackathon\\\\Data\\\\signalstrength.csv\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_df1 = (h_cust_churn.join(h_cdr, \"phone number\")\n",
    "        .join(h_complaint, \"phone number\")\n",
    "        .join(h_revenue, \"phone number\")\n",
    "        .join(h_signal, \"phone number\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+--------------+---------+--------------+---+------+-------------------+------------+------------------------+------------------+---------------+-----------+-------------+---------------------+-----------------+---------------+-----------------+---------------+-------------------+-----------------+------------------+----------------+----------------------+--------------------------+-------------------+-----------------------------------------------------------------------------+-------------+-------------------+----------+----------------------+-----+--------------+----------------------------+---------------------+-------------------------------------------------+----------------+----------------+------------------+-----------------+-----+-----------------+-----------------+----------------------------------+---------------------------------+\n",
      "|phone number|churn|state|account length|area code|account (days)|Age|Gender|         Occupation|Joining date|Subsciption renewal date|international plan|voice mail plan|%call drops|%Packet_drops|number vmail messages|total day minutes|total day calls|total eve minutes|total eve calls|total night minutes|total night calls|total intl minutes|total intl calls|customer service calls|Number of complaint raised|Time for resolution|payment_made_but_order_not_placed_and_amount_is_deducted_from_my_bank_account|Billing_issue|Calls_are_not_going|drop_calls|No_internet_connection|order|payment_refund|recharge_offer_service_fraud|Slow_network_coverage|uninformed___unsubscribed_weekly_amount_deduction|total day charge|total eve charge|total night charge|total intl charge| ARPU|signalstrength_4g|signalstrength_3g|Duration of good signal strength% |Duration of bad Signal strength %|\n",
      "+------------+-----+-----+--------------+---------+--------------+---+------+-------------------+------------+------------------------+------------------+---------------+-----------+-------------+---------------------+-----------------+---------------+-----------------+---------------+-------------------+-----------------+------------------+----------------+----------------------+--------------------------+-------------------+-----------------------------------------------------------------------------+-------------+-------------------+----------+----------------------+-----+--------------+----------------------------+---------------------+-------------------------------------------------+----------------+----------------+------------------+-----------------+-----+-----------------+-----------------+----------------------------------+---------------------------------+\n",
      "|    382-4657|FALSE|   KS|           128|      415|           896| 53|Female|Senior Professional|    4/1/2016|                3/1/2018|                no|            yes|      0.008|        0.007|                   25|            265.1|            110|            197.4|             99|              244.7|               91|                10|               3|                     1|                         1|                 21|                                                                            0|            0|                  0|         0|                     0|    0|             1|                           0|                    0|                                                0|           45.07|           16.78|             11.01|              2.7|75.56|              -66|              -52|                             0.969|                            0.031|\n",
      "+------------+-----+-----+--------------+---------+--------------+---+------+-------------------+------------+------------------------+------------------+---------------+-----------+-------------+---------------------+-----------------+---------------+-----------------+---------------+-------------------+-----------------+------------------+----------------+----------------------+--------------------------+-------------------+-----------------------------------------------------------------------------+-------------+-------------------+----------+----------------------+-----+--------------+----------------------------+---------------------+-------------------------------------------------+----------------+----------------+------------------+-----------------+-----+-----------------+-----------------+----------------------------------+---------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "h_df1.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleting a data column from the first complete dataframe\n",
    "\n",
    "df.drop('age').collect() # connect() would keep it in the RAM for faster computation . This is not needed now\n",
    "\n",
    "df.drop(df.age).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- phone number: string (nullable = true)\n",
      " |-- churn: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- account length: string (nullable = true)\n",
      " |-- area code: string (nullable = true)\n",
      " |-- account (days): string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Occupation: string (nullable = true)\n",
      " |-- Joining date: string (nullable = true)\n",
      " |-- Subsciption renewal date: string (nullable = true)\n",
      " |-- international plan: string (nullable = true)\n",
      " |-- voice mail plan: string (nullable = true)\n",
      " |-- %call drops: string (nullable = true)\n",
      " |-- %Packet_drops: string (nullable = true)\n",
      " |-- number vmail messages: string (nullable = true)\n",
      " |-- total day minutes: string (nullable = true)\n",
      " |-- total day calls: string (nullable = true)\n",
      " |-- total eve minutes: string (nullable = true)\n",
      " |-- total eve calls: string (nullable = true)\n",
      " |-- total night minutes: string (nullable = true)\n",
      " |-- total night calls: string (nullable = true)\n",
      " |-- total intl minutes: string (nullable = true)\n",
      " |-- total intl calls: string (nullable = true)\n",
      " |-- customer service calls: string (nullable = true)\n",
      " |-- Number of complaint raised: string (nullable = true)\n",
      " |-- Time for resolution: string (nullable = true)\n",
      " |-- payment_made_but_order_not_placed_and_amount_is_deducted_from_my_bank_account: string (nullable = true)\n",
      " |-- Billing_issue: string (nullable = true)\n",
      " |-- Calls_are_not_going: string (nullable = true)\n",
      " |-- drop_calls: string (nullable = true)\n",
      " |-- No_internet_connection: string (nullable = true)\n",
      " |-- order: string (nullable = true)\n",
      " |-- payment_refund: string (nullable = true)\n",
      " |-- recharge_offer_service_fraud: string (nullable = true)\n",
      " |-- Slow_network_coverage: string (nullable = true)\n",
      " |-- uninformed___unsubscribed_weekly_amount_deduction: string (nullable = true)\n",
      " |-- total day charge: string (nullable = true)\n",
      " |-- total eve charge: string (nullable = true)\n",
      " |-- total night charge: string (nullable = true)\n",
      " |-- total intl charge: string (nullable = true)\n",
      " |-- ARPU: string (nullable = true)\n",
      " |-- signalstrength_4g: string (nullable = true)\n",
      " |-- signalstrength_3g: string (nullable = true)\n",
      " |-- Duration of good signal strength% : string (nullable = true)\n",
      " |-- Duration of bad Signal strength %: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Understanding the feature datatype\n",
    "\n",
    "h_df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_df1.count() # to check number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|summary|churn|\n",
      "+-------+-----+\n",
      "|  count| 3333|\n",
      "|   mean| null|\n",
      "| stddev| null|\n",
      "|    min|FALSE|\n",
      "|    max| TRUE|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Summary statistcs\n",
    "h_df1.describe('churn').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "kk= h_df1.summary().repartition(1) # using summary function to include more statistics as compared to describe()\n",
    "\n",
    "# we are doing repartition to 1 here as while checking kk.rdd.getNumPartitions() we saw there are 4 partition and needed to join the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the file in local drive as CSV\n",
    "kk.write.save(\"C:\\\\Users\\\\inkpathak\\\\Desktop\\\\Hackathon\\\\Data\\\\descriptiveStatistics1.csv\", format=\"csv\", header = True)\n",
    "\n",
    "# This function cant overwrite existing table and hence create new table everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk.rdd.getNumPartitions()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the number of distinct levels in selected coluns\n",
    "\n",
    "h_df1.select('voice mail plan').distinct().count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_df1.select('total night calls').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type casting of the data for analysis\n",
    "\n",
    "this is required as different algorithm does not work on string data and hence need to convert variables into float selectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "h_final = h_df1.withColumn(\"account length\", h_df1[\"account length\"].cast(FloatType()))\\\n",
    ".withColumn(\"account (days)\", h_df1[\"account (days)\"].cast(FloatType()))\\\n",
    ".withColumn(\"Age\", h_df1[\"Age\"].cast(FloatType()))\\\n",
    ".withColumn(\"%call drops\", h_df1[\"%call drops\"].cast(FloatType()))\\\n",
    ".withColumn(\"%Packet_drops\", h_df1[\"%Packet_drops\"].cast(FloatType()))\\\n",
    ".withColumn(\"number vmail messages\", h_df1[\"number vmail messages\"].cast(FloatType()))\\\n",
    ".withColumn(\"total day minutes\", h_df1[\"total day minutes\"].cast(FloatType()))\\\n",
    ".withColumn(\"total day calls\", h_df1[\"total day calls\"].cast(FloatType()))\\\n",
    ".withColumn(\"total eve minutes\", h_df1[\"total eve minutes\"].cast(FloatType()))\\\n",
    ".withColumn(\"total eve calls\", h_df1[\"total eve calls\"].cast(FloatType()))\\\n",
    ".withColumn(\"total night minutes\", h_df1[\"total night minutes\"].cast(FloatType()))\\\n",
    ".withColumn(\"total night calls\", h_df1[\"total night calls\"].cast(FloatType()))\\\n",
    ".withColumn(\"total intl minutes\", h_df1[\"total intl minutes\"].cast(FloatType()))\\\n",
    ".withColumn(\"total intl calls\", h_df1[\"total intl calls\"].cast(FloatType()))\\\n",
    ".withColumn(\"customer service calls\", h_df1[\"customer service calls\"].cast(FloatType()))\\\n",
    ".withColumn(\"Number of complaint raised\", h_df1[\"Number of complaint raised\"].cast(FloatType()))\\\n",
    ".withColumn(\"Time for resolution\", h_df1[\"Time for resolution\"].cast(FloatType()))\\\n",
    ".withColumn(\"payment_made_but_order_not_placed_and_amount_is_deducted_from_my_bank_account\", h_df1[\"payment_made_but_order_not_placed_and_amount_is_deducted_from_my_bank_account\"].cast(FloatType()))\\\n",
    ".withColumn(\"Billing_issue\", h_df1[\"Billing_issue\"].cast(FloatType()))\\\n",
    ".withColumn(\"Calls_are_not_going\", h_df1[\"Calls_are_not_going\"].cast(FloatType()))\\\n",
    ".withColumn(\"drop_calls\", h_df1[\"drop_calls\"].cast(FloatType()))\\\n",
    ".withColumn(\"No_internet_connection\", h_df1[\"No_internet_connection\"].cast(FloatType()))\\\n",
    ".withColumn(\"order\", h_df1[\"order\"].cast(FloatType()))\\\n",
    ".withColumn(\"payment_refund\", h_df1[\"payment_refund\"].cast(FloatType()))\\\n",
    ".withColumn(\"recharge_offer_service_fraud\", h_df1[\"recharge_offer_service_fraud\"].cast(FloatType()))\\\n",
    ".withColumn(\"Slow_network_coverage\", h_df1[\"Slow_network_coverage\"].cast(FloatType()))\\\n",
    ".withColumn(\"uninformed___unsubscribed_weekly_amount_deduction\", h_df1[\"uninformed___unsubscribed_weekly_amount_deduction\"].cast(FloatType()))\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- phone number: string (nullable = true)\n",
      " |-- churn: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- account length: float (nullable = true)\n",
      " |-- area code: string (nullable = true)\n",
      " |-- account (days): float (nullable = true)\n",
      " |-- Age: float (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Occupation: string (nullable = true)\n",
      " |-- Joining date: string (nullable = true)\n",
      " |-- Subsciption renewal date: string (nullable = true)\n",
      " |-- international plan: string (nullable = true)\n",
      " |-- voice mail plan: string (nullable = true)\n",
      " |-- %call drops: float (nullable = true)\n",
      " |-- %Packet_drops: float (nullable = true)\n",
      " |-- number vmail messages: float (nullable = true)\n",
      " |-- total day minutes: float (nullable = true)\n",
      " |-- total day calls: float (nullable = true)\n",
      " |-- total eve minutes: float (nullable = true)\n",
      " |-- total eve calls: float (nullable = true)\n",
      " |-- total night minutes: float (nullable = true)\n",
      " |-- total night calls: float (nullable = true)\n",
      " |-- total intl minutes: float (nullable = true)\n",
      " |-- total intl calls: float (nullable = true)\n",
      " |-- customer service calls: float (nullable = true)\n",
      " |-- Number of complaint raised: float (nullable = true)\n",
      " |-- Time for resolution: float (nullable = true)\n",
      " |-- payment_made_but_order_not_placed_and_amount_is_deducted_from_my_bank_account: float (nullable = true)\n",
      " |-- Billing_issue: float (nullable = true)\n",
      " |-- Calls_are_not_going: float (nullable = true)\n",
      " |-- drop_calls: float (nullable = true)\n",
      " |-- No_internet_connection: float (nullable = true)\n",
      " |-- order: float (nullable = true)\n",
      " |-- payment_refund: float (nullable = true)\n",
      " |-- recharge_offer_service_fraud: float (nullable = true)\n",
      " |-- Slow_network_coverage: float (nullable = true)\n",
      " |-- uninformed___unsubscribed_weekly_amount_deduction: float (nullable = true)\n",
      " |-- total day charge: string (nullable = true)\n",
      " |-- total eve charge: string (nullable = true)\n",
      " |-- total night charge: string (nullable = true)\n",
      " |-- total intl charge: string (nullable = true)\n",
      " |-- ARPU: string (nullable = true)\n",
      " |-- signalstrength_4g: string (nullable = true)\n",
      " |-- signalstrength_3g: string (nullable = true)\n",
      " |-- Duration of good signal strength% : string (nullable = true)\n",
      " |-- Duration of bad Signal strength %: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "h_final.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing value\n",
    "\n",
    "We are going to look into some option to handle missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First option to deal with missing value is to delete the rows with missing value\n",
    "\n",
    "# before doing this step assigning the data frame to another name \n",
    "\n",
    "h_df = h_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What if I want to drop the all rows with null value\n",
    "\n",
    "# cheking number of missing value in the dataframe\n",
    "\n",
    "h_df1.count() - h_final.dropna().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate number of missing value by column\n",
    "\n",
    "def count_nulls(df):\n",
    "    null_counts = []          #make an empty list to hold our results\n",
    "    for col in df.dtypes:     #iterate through the column data types we saw above, e.g. ('C0', 'bigint')\n",
    "        cname = col[0]        #splits out the column name, e.g. 'C0'    \n",
    "        ctype = col[1]        #splits out the column type, e.g. 'bigint'\n",
    "        if ctype != 'string': #skip processing string columns for efficiency (can't have nulls)\n",
    "            nulls = df.where( df[cname].isNull() ).count()\n",
    "            result = tuple([cname, nulls])  #new tuple, (column name, null count)\n",
    "            null_counts.append(result)      #put the new tuple in our result list\n",
    "    return null_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts = count_nulls(h_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('account length', 0),\n",
       " ('account (days)', 0),\n",
       " ('Age', 0),\n",
       " ('%call drops', 0),\n",
       " ('%Packet_drops', 2),\n",
       " ('number vmail messages', 1),\n",
       " ('total day minutes', 0),\n",
       " ('total day calls', 0),\n",
       " ('total eve minutes', 0),\n",
       " ('total eve calls', 0),\n",
       " ('total night minutes', 0),\n",
       " ('total night calls', 0),\n",
       " ('total intl minutes', 0),\n",
       " ('total intl calls', 0),\n",
       " ('customer service calls', 0),\n",
       " ('Number of complaint raised', 0),\n",
       " ('Time for resolution', 0),\n",
       " ('payment_made_but_order_not_placed_and_amount_is_deducted_from_my_bank_account',\n",
       "  0),\n",
       " ('Billing_issue', 0),\n",
       " ('Calls_are_not_going', 0),\n",
       " ('drop_calls', 0),\n",
       " ('No_internet_connection', 0),\n",
       " ('order', 0),\n",
       " ('payment_refund', 0),\n",
       " ('recharge_offer_service_fraud', 0),\n",
       " ('Slow_network_coverage', 0),\n",
       " ('uninformed___unsubscribed_weekly_amount_deduction', 0)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.stat import Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h_df2= h_final.select('churn','%call drops', 'total day minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['churn', '%call drops', 'total day minutes']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = h_df2.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[1243] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "\"cannot resolve '`features`' given input columns: [number vmail messages, total day minutes, churn, %Packet_drops, %call drops];;\\n'Project ['features]\\n+- AnalysisBarrier\\n      +- Project [churn#5892, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494]\\n         +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\\n            +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\\n               +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\\n                  +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\\n                     +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\\n                        +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\\n                           +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\\n                              +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\\n                                 +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\\n                                    +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\\n                                       +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\\n                                          +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\\n                                             +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\\n                                                +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, cast(total intl calls#5828 as float) AS total intl calls#14823, ... 22 more fields]\\n                                                   +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, cast(total intl minutes#5827 as float) AS total intl minutes#14776, total intl calls#5828, ... 22 more fields]\\n                                                      +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, cast(total night calls#5826 as float) AS total night calls#14729, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\\n                                                         +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, cast(total night minutes#5825 as float) AS total night minutes#14682, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\\n                                                            +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, cast(total eve calls#5824 as float) AS total eve calls#14635, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\\n                                                               +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, cast(total eve minutes#5823 as float) AS total eve minutes#14588, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\\n                                                                  +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, cast(total day calls#5822 as float) AS total day calls#14541, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\\n                                                                     +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, cast(total day minutes#5821 as float) AS total day minutes#14494, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\\n                                                                        +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, cast(number vmail messages#5820 as float) AS number vmail messages#14447, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\\n                                                                           +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, cast(%Packet_drops#5819 as float) AS %Packet_drops#14400, number vmail messages#5820, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\\n                                                                              +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, cast(%call drops#5818 as float) AS %call drops#14353, %Packet_drops#5819, number vmail messages#5820, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\\n                                                                                 +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, cast(Age#5898 as float) AS Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#5818, %Packet_drops#5819, number vmail messages#5820, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\\n                                                                                    +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, cast(account (days)#5897 as float) AS account (days)#14259, Age#5898, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#5818, %Packet_drops#5819, number vmail messages#5820, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\\n                                                                                       +- Project [phone number#5896, churn#5892, state#5893, cast(account length#5894 as float) AS account length#14212, area code#5895, account (days)#5897, Age#5898, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#5818, %Packet_drops#5819, number vmail messages#5820, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\\n                                                                                          +- Project [phone number#5896, churn#5892, state#5893, account length#5894, area code#5895, account (days)#5897, Age#5898, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#5818, %Packet_drops#5819, number vmail messages#5820, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\\n                                                                                             +- Join Inner, (phone number#5896 = phone number#5946)\\n                                                                                                :- Project [phone number#5896, churn#5892, state#5893, account length#5894, area code#5895, account (days)#5897, Age#5898, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#5818, %Packet_drops#5819, number vmail messages#5820, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 18 more fields]\\n                                                                                                :  +- Join Inner, (phone number#5896 = phone number#5929)\\n                                                                                                :     :- Project [phone number#5896, churn#5892, state#5893, account length#5894, area code#5895, account (days)#5897, Age#5898, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#5818, %Packet_drops#5819, number vmail messages#5820, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 13 more fields]\\n                                                                                                :     :  +- Join Inner, (phone number#5896 = phone number#5854)\\n                                                                                                :     :     :- Project [phone number#5896, churn#5892, state#5893, account length#5894, area code#5895, account (days)#5897, Age#5898, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#5818, %Packet_drops#5819, number vmail messages#5820, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828]\\n                                                                                                :     :     :  +- Join Inner, (phone number#5896 = phone number#5829)\\n                                                                                                :     :     :     :- Relation[churn#5892,state#5893,account length#5894,area code#5895,phone number#5896,account (days)#5897,Age#5898,Gender#5899,Occupation#5900,Joining date#5901,Subsciption renewal date#5902] csv\\n                                                                                                :     :     :     +- Relation[international plan#5816,voice mail plan#5817,%call drops#5818,%Packet_drops#5819,number vmail messages#5820,total day minutes#5821,total day calls#5822,total eve minutes#5823,total eve calls#5824,total night minutes#5825,total night calls#5826,total intl minutes#5827,total intl calls#5828,phone number#5829] csv\\n                                                                                                :     :     +- Relation[phone number#5854,customer service calls#5855,Number of complaint raised#5856,Time for resolution#5857,payment_made_but_order_not_placed_and_amount_is_deducted_from_my_bank_account#5858,Billing_issue#5859,Calls_are_not_going#5860,drop_calls#5861,No_internet_connection#5862,order#5863,payment_refund#5864,recharge_offer_service_fraud#5865,Slow_network_coverage#5866,uninformed___unsubscribed_weekly_amount_deduction#5867] csv\\n                                                                                                :     +- Relation[total day charge#5924,total eve charge#5925,total night charge#5926,total intl charge#5927,ARPU#5928,phone number#5929] csv\\n                                                                                                +- Relation[phone number#5946,signalstrength_4g#5947,signalstrength_3g#5948,Duration of good signal strength% #5949,Duration of bad Signal strength %#5950] csv\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mE:\\software_setup_for_hackathon\\spark\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software_setup_for_hackathon\\spark\\python\\lib\\py4j-0.10.6-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    319\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    321\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.ml.stat.Correlation.corr.\n: org.apache.spark.sql.AnalysisException: cannot resolve '`features`' given input columns: [number vmail messages, total day minutes, churn, %Packet_drops, %call drops];;\n'Project ['features]\n+- AnalysisBarrier\n      +- Project [churn#5892, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494]\n         +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\n            +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\n               +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\n                  +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\n                     +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\n                        +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\n                           +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\n                              +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\n                                 +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\n                                    +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\n                                       +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\n                                          +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\n                                             +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\n                                                +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, cast(total intl calls#5828 as float) AS total intl calls#14823, ... 22 more fields]\n                                                   +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, cast(total intl minutes#5827 as float) AS total intl minutes#14776, total intl calls#5828, ... 22 more fields]\n                                                      +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, cast(total night calls#5826 as float) AS total night calls#14729, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\n                                                         +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, cast(total night minutes#5825 as float) AS total night minutes#14682, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\n                                                            +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, cast(total eve calls#5824 as float) AS total eve calls#14635, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\n                                                               +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, cast(total eve minutes#5823 as float) AS total eve minutes#14588, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\n                                                                  +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, cast(total day calls#5822 as float) AS total day calls#14541, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\n                                                                     +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, cast(total day minutes#5821 as float) AS total day minutes#14494, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\n                                                                        +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, cast(number vmail messages#5820 as float) AS number vmail messages#14447, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\n                                                                           +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, cast(%Packet_drops#5819 as float) AS %Packet_drops#14400, number vmail messages#5820, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\n                                                                              +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, cast(%call drops#5818 as float) AS %call drops#14353, %Packet_drops#5819, number vmail messages#5820, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\n                                                                                 +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, cast(Age#5898 as float) AS Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#5818, %Packet_drops#5819, number vmail messages#5820, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\n                                                                                    +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, cast(account (days)#5897 as float) AS account (days)#14259, Age#5898, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#5818, %Packet_drops#5819, number vmail messages#5820, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\n                                                                                       +- Project [phone number#5896, churn#5892, state#5893, cast(account length#5894 as float) AS account length#14212, area code#5895, account (days)#5897, Age#5898, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#5818, %Packet_drops#5819, number vmail messages#5820, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\n                                                                                          +- Project [phone number#5896, churn#5892, state#5893, account length#5894, area code#5895, account (days)#5897, Age#5898, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#5818, %Packet_drops#5819, number vmail messages#5820, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\n                                                                                             +- Join Inner, (phone number#5896 = phone number#5946)\n                                                                                                :- Project [phone number#5896, churn#5892, state#5893, account length#5894, area code#5895, account (days)#5897, Age#5898, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#5818, %Packet_drops#5819, number vmail messages#5820, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 18 more fields]\n                                                                                                :  +- Join Inner, (phone number#5896 = phone number#5929)\n                                                                                                :     :- Project [phone number#5896, churn#5892, state#5893, account length#5894, area code#5895, account (days)#5897, Age#5898, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#5818, %Packet_drops#5819, number vmail messages#5820, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 13 more fields]\n                                                                                                :     :  +- Join Inner, (phone number#5896 = phone number#5854)\n                                                                                                :     :     :- Project [phone number#5896, churn#5892, state#5893, account length#5894, area code#5895, account (days)#5897, Age#5898, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#5818, %Packet_drops#5819, number vmail messages#5820, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828]\n                                                                                                :     :     :  +- Join Inner, (phone number#5896 = phone number#5829)\n                                                                                                :     :     :     :- Relation[churn#5892,state#5893,account length#5894,area code#5895,phone number#5896,account (days)#5897,Age#5898,Gender#5899,Occupation#5900,Joining date#5901,Subsciption renewal date#5902] csv\n                                                                                                :     :     :     +- Relation[international plan#5816,voice mail plan#5817,%call drops#5818,%Packet_drops#5819,number vmail messages#5820,total day minutes#5821,total day calls#5822,total eve minutes#5823,total eve calls#5824,total night minutes#5825,total night calls#5826,total intl minutes#5827,total intl calls#5828,phone number#5829] csv\n                                                                                                :     :     +- Relation[phone number#5854,customer service calls#5855,Number of complaint raised#5856,Time for resolution#5857,payment_made_but_order_not_placed_and_amount_is_deducted_from_my_bank_account#5858,Billing_issue#5859,Calls_are_not_going#5860,drop_calls#5861,No_internet_connection#5862,order#5863,payment_refund#5864,recharge_offer_service_fraud#5865,Slow_network_coverage#5866,uninformed___unsubscribed_weekly_amount_deduction#5867] csv\n                                                                                                :     +- Relation[total day charge#5924,total eve charge#5925,total night charge#5926,total intl charge#5927,ARPU#5928,phone number#5929] csv\n                                                                                                +- Relation[phone number#5946,signalstrength_4g#5947,signalstrength_3g#5948,Duration of good signal strength% #5949,Duration of bad Signal strength %#5950] csv\n\r\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\r\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:88)\r\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:85)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:289)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:289)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:288)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:95)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:95)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:106)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:116)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1$1.apply(QueryPlan.scala:120)\r\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\r\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\r\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:120)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:125)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:125)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:95)\r\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:85)\r\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:80)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:127)\r\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:80)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:91)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:104)\r\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)\r\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)\r\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:74)\r\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:3295)\r\n\tat org.apache.spark.sql.Dataset.select(Dataset.scala:1307)\r\n\tat org.apache.spark.sql.Dataset.select(Dataset.scala:1325)\r\n\tat org.apache.spark.ml.stat.Correlation$.corr(Correlation.scala:70)\r\n\tat org.apache.spark.ml.stat.Correlation.corr(Correlation.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:483)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-36e396f281c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStatistics\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mr1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCorrelation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_df2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"features\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\software_setup_for_hackathon\\spark\\python\\pyspark\\ml\\stat.py\u001b[0m in \u001b[0;36mcorr\u001b[1;34m(dataset, column, method)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mjavaCorrObj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_jvm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCorrelation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_java2py\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjavaCorrObj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software_setup_for_hackathon\\spark\\python\\lib\\py4j-0.10.6-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1158\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1160\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software_setup_for_hackathon\\spark\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[0;32m     68\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: \"cannot resolve '`features`' given input columns: [number vmail messages, total day minutes, churn, %Packet_drops, %call drops];;\\n'Project ['features]\\n+- AnalysisBarrier\\n      +- Project [churn#5892, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494]\\n         +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\\n            +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\\n               +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\\n                  +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\\n                     +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\\n                        +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\\n                           +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\\n                              +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\\n                                 +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\\n                                    +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\\n                                       +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\\n                                          +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\\n                                             +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, total intl calls#14823, ... 22 more fields]\\n                                                +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, total intl minutes#14776, cast(total intl calls#5828 as float) AS total intl calls#14823, ... 22 more fields]\\n                                                   +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, total night calls#14729, cast(total intl minutes#5827 as float) AS total intl minutes#14776, total intl calls#5828, ... 22 more fields]\\n                                                      +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, total night minutes#14682, cast(total night calls#5826 as float) AS total night calls#14729, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\\n                                                         +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, total eve calls#14635, cast(total night minutes#5825 as float) AS total night minutes#14682, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\\n                                                            +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, total eve minutes#14588, cast(total eve calls#5824 as float) AS total eve calls#14635, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\\n                                                               +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, total day calls#14541, cast(total eve minutes#5823 as float) AS total eve minutes#14588, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\\n                                                                  +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, total day minutes#14494, cast(total day calls#5822 as float) AS total day calls#14541, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\\n                                                                     +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, number vmail messages#14447, cast(total day minutes#5821 as float) AS total day minutes#14494, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\\n                                                                        +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, %Packet_drops#14400, cast(number vmail messages#5820 as float) AS number vmail messages#14447, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\\n                                                                           +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#14353, cast(%Packet_drops#5819 as float) AS %Packet_drops#14400, number vmail messages#5820, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\\n                                                                              +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, cast(%call drops#5818 as float) AS %call drops#14353, %Packet_drops#5819, number vmail messages#5820, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\\n                                                                                 +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, account (days)#14259, cast(Age#5898 as float) AS Age#14306, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#5818, %Packet_drops#5819, number vmail messages#5820, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\\n                                                                                    +- Project [phone number#5896, churn#5892, state#5893, account length#14212, area code#5895, cast(account (days)#5897 as float) AS account (days)#14259, Age#5898, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#5818, %Packet_drops#5819, number vmail messages#5820, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\\n                                                                                       +- Project [phone number#5896, churn#5892, state#5893, cast(account length#5894 as float) AS account length#14212, area code#5895, account (days)#5897, Age#5898, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#5818, %Packet_drops#5819, number vmail messages#5820, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\\n                                                                                          +- Project [phone number#5896, churn#5892, state#5893, account length#5894, area code#5895, account (days)#5897, Age#5898, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#5818, %Packet_drops#5819, number vmail messages#5820, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 22 more fields]\\n                                                                                             +- Join Inner, (phone number#5896 = phone number#5946)\\n                                                                                                :- Project [phone number#5896, churn#5892, state#5893, account length#5894, area code#5895, account (days)#5897, Age#5898, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#5818, %Packet_drops#5819, number vmail messages#5820, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 18 more fields]\\n                                                                                                :  +- Join Inner, (phone number#5896 = phone number#5929)\\n                                                                                                :     :- Project [phone number#5896, churn#5892, state#5893, account length#5894, area code#5895, account (days)#5897, Age#5898, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#5818, %Packet_drops#5819, number vmail messages#5820, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828, ... 13 more fields]\\n                                                                                                :     :  +- Join Inner, (phone number#5896 = phone number#5854)\\n                                                                                                :     :     :- Project [phone number#5896, churn#5892, state#5893, account length#5894, area code#5895, account (days)#5897, Age#5898, Gender#5899, Occupation#5900, Joining date#5901, Subsciption renewal date#5902, international plan#5816, voice mail plan#5817, %call drops#5818, %Packet_drops#5819, number vmail messages#5820, total day minutes#5821, total day calls#5822, total eve minutes#5823, total eve calls#5824, total night minutes#5825, total night calls#5826, total intl minutes#5827, total intl calls#5828]\\n                                                                                                :     :     :  +- Join Inner, (phone number#5896 = phone number#5829)\\n                                                                                                :     :     :     :- Relation[churn#5892,state#5893,account length#5894,area code#5895,phone number#5896,account (days)#5897,Age#5898,Gender#5899,Occupation#5900,Joining date#5901,Subsciption renewal date#5902] csv\\n                                                                                                :     :     :     +- Relation[international plan#5816,voice mail plan#5817,%call drops#5818,%Packet_drops#5819,number vmail messages#5820,total day minutes#5821,total day calls#5822,total eve minutes#5823,total eve calls#5824,total night minutes#5825,total night calls#5826,total intl minutes#5827,total intl calls#5828,phone number#5829] csv\\n                                                                                                :     :     +- Relation[phone number#5854,customer service calls#5855,Number of complaint raised#5856,Time for resolution#5857,payment_made_but_order_not_placed_and_amount_is_deducted_from_my_bank_account#5858,Billing_issue#5859,Calls_are_not_going#5860,drop_calls#5861,No_internet_connection#5862,order#5863,payment_refund#5864,recharge_offer_service_fraud#5865,Slow_network_coverage#5866,uninformed___unsubscribed_weekly_amount_deduction#5867] csv\\n                                                                                                :     +- Relation[total day charge#5924,total eve charge#5925,total night charge#5926,total intl charge#5927,ARPU#5928,phone number#5929] csv\\n                                                                                                +- Relation[phone number#5946,signalstrength_4g#5947,signalstrength_3g#5948,Duration of good signal strength% #5949,Duration of bad Signal strength %#5950] csv\\n\""
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.stat import Statistics\n",
    "\n",
    "r1 = Correlation.corr(h_df2, \"features\").head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "jj=h_df2.corr(\"%call drops\",\"total day minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11816459600567038"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.stat import Statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# result can be used w/ seaborn's heatmap\n",
    "def compute_correlation_matrix(df, method='pearson'):\n",
    "    # wrapper around\n",
    "    # https://forums.databricks.com/questions/3092/how-to-calculate-correlation-matrix-with-all-colum.html\n",
    "    df_rdd = df.rdd.map(lambda row: row[0:])\n",
    "    corr_mat = Statistics.corr(df_rdd, method=method)\n",
    "    corr_mat_df = pd.DataFrame(corr_mat,\n",
    "                    columns=df.columns, \n",
    "                    index=df.columns)\n",
    "    return corr_mat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SparkSession' object has no attribute 'Statistics'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-aee353ca76b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mjjj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_correlation_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mh_df2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-ad82565ad022>\u001b[0m in \u001b[0;36mcompute_correlation_matrix\u001b[1;34m(df, method)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# https://forums.databricks.com/questions/3092/how-to-calculate-correlation-matrix-with-all-colum.html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mdf_rdd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mcorr_mat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatistics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_rdd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     corr_mat_df = pd.DataFrame(corr_mat,\n\u001b[0;32m     11\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SparkSession' object has no attribute 'Statistics'"
     ]
    }
   ],
   "source": [
    "jjj=compute_correlation_matrix(df=h_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(h_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_correlation_matrix(df, method='pearson'):\n",
    "    # wrapper around\n",
    "    # https://forums.databricks.com/questions/3092/how-to-calculate-correlation-matrix-with-all-colum.html\n",
    "    df_rdd = df.rdd.map(lambda row: row[0:])\n",
    "    corr_mat = Statistics.corr(df_rdd, method=method)\n",
    "    return corr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1561.corr.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 471.0 failed 1 times, most recent failure: Lost task 0.0 in stage 471.0 (TID 3014, localhost, executor driver): org.apache.spark.SparkException: Python worker did not connect back in time\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:143)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:72)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:117)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:86)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:135)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:404)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:199)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:138)\r\n\t... 15 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2027)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2048)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1358)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1331)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1372)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.first(RDD.scala:1371)\r\n\tat org.apache.spark.mllib.linalg.distributed.RowMatrix.numCols(RowMatrix.scala:61)\r\n\tat org.apache.spark.mllib.linalg.distributed.RowMatrix.computeCovariance(RowMatrix.scala:331)\r\n\tat org.apache.spark.mllib.stat.correlation.PearsonCorrelation$.computeCorrelationMatrix(PearsonCorrelation.scala:49)\r\n\tat org.apache.spark.mllib.stat.correlation.Correlations$.corrMatrix(Correlation.scala:66)\r\n\tat org.apache.spark.mllib.stat.Statistics$.corr(Statistics.scala:74)\r\n\tat org.apache.spark.mllib.api.python.PythonMLLibAPI.corr(PythonMLLibAPI.scala:846)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:483)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: org.apache.spark.SparkException: Python worker did not connect back in time\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:143)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:72)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:117)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:86)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:135)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:404)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:199)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:138)\r\n\t... 15 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-a6bbd55d2987>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mjjj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_correlation_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mh_df2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pearson'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-101-36c0730b3010>\u001b[0m in \u001b[0;36mcompute_correlation_matrix\u001b[1;34m(df, method)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# https://forums.databricks.com/questions/3092/how-to-calculate-correlation-matrix-with-all-colum.html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdf_rdd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mcorr_mat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStatistics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_rdd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcorr_mat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software_setup_for_hackathon\\spark\\python\\pyspark\\mllib\\stat\\_statistics.py\u001b[0m in \u001b[0;36mcorr\u001b[1;34m(x, y, method)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcallMLlibFunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"corr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert_to_vector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mcallMLlibFunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"corr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software_setup_for_hackathon\\spark\\python\\pyspark\\mllib\\common.py\u001b[0m in \u001b[0;36mcallMLlibFunc\u001b[1;34m(name, *args)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[0mapi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonMLLibAPI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcallJavaFunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software_setup_for_hackathon\\spark\\python\\pyspark\\mllib\\common.py\u001b[0m in \u001b[0;36mcallJavaFunc\u001b[1;34m(sc, func, *args)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;34m\"\"\" Call Java Function \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_java2py\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software_setup_for_hackathon\\spark\\python\\lib\\py4j-0.10.6-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1158\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1160\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software_setup_for_hackathon\\spark\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software_setup_for_hackathon\\spark\\python\\lib\\py4j-0.10.6-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    318\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    319\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    321\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o1561.corr.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 471.0 failed 1 times, most recent failure: Lost task 0.0 in stage 471.0 (TID 3014, localhost, executor driver): org.apache.spark.SparkException: Python worker did not connect back in time\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:143)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:72)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:117)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:86)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:135)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:404)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:199)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:138)\r\n\t... 15 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2027)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2048)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1358)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1331)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1372)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.first(RDD.scala:1371)\r\n\tat org.apache.spark.mllib.linalg.distributed.RowMatrix.numCols(RowMatrix.scala:61)\r\n\tat org.apache.spark.mllib.linalg.distributed.RowMatrix.computeCovariance(RowMatrix.scala:331)\r\n\tat org.apache.spark.mllib.stat.correlation.PearsonCorrelation$.computeCorrelationMatrix(PearsonCorrelation.scala:49)\r\n\tat org.apache.spark.mllib.stat.correlation.Correlations$.corrMatrix(Correlation.scala:66)\r\n\tat org.apache.spark.mllib.stat.Statistics$.corr(Statistics.scala:74)\r\n\tat org.apache.spark.mllib.api.python.PythonMLLibAPI.corr(PythonMLLibAPI.scala:846)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:483)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: org.apache.spark.SparkException: Python worker did not connect back in time\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:143)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:72)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:117)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:86)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:135)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:404)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:199)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:138)\r\n\t... 15 more\r\n"
     ]
    }
   ],
   "source": [
    "jjj=compute_correlation_matrix(df=h_df2, method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1746.corr.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 482.0 failed 1 times, most recent failure: Lost task 0.0 in stage 482.0 (TID 3025, localhost, executor driver): org.apache.spark.SparkException: Python worker did not connect back in time\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:143)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:72)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:117)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:86)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:135)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:404)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:199)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:138)\r\n\t... 15 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2027)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2048)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1358)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1331)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1372)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.first(RDD.scala:1371)\r\n\tat org.apache.spark.mllib.linalg.distributed.RowMatrix.numCols(RowMatrix.scala:61)\r\n\tat org.apache.spark.mllib.linalg.distributed.RowMatrix.computeCovariance(RowMatrix.scala:331)\r\n\tat org.apache.spark.mllib.stat.correlation.PearsonCorrelation$.computeCorrelationMatrix(PearsonCorrelation.scala:49)\r\n\tat org.apache.spark.mllib.stat.correlation.Correlations$.corrMatrix(Correlation.scala:66)\r\n\tat org.apache.spark.mllib.stat.Statistics$.corr(Statistics.scala:74)\r\n\tat org.apache.spark.mllib.api.python.PythonMLLibAPI.corr(PythonMLLibAPI.scala:846)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:483)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: org.apache.spark.SparkException: Python worker did not connect back in time\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:143)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:72)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:117)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:86)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:135)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:404)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:199)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:138)\r\n\t... 15 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-6419875a2f98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStatistics\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mcorr_mat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mStatistics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"pearson\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\software_setup_for_hackathon\\spark\\python\\pyspark\\mllib\\stat\\_statistics.py\u001b[0m in \u001b[0;36mcorr\u001b[1;34m(x, y, method)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcallMLlibFunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"corr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert_to_vector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mcallMLlibFunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"corr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software_setup_for_hackathon\\spark\\python\\pyspark\\mllib\\common.py\u001b[0m in \u001b[0;36mcallMLlibFunc\u001b[1;34m(name, *args)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[0mapi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonMLLibAPI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcallJavaFunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software_setup_for_hackathon\\spark\\python\\pyspark\\mllib\\common.py\u001b[0m in \u001b[0;36mcallJavaFunc\u001b[1;34m(sc, func, *args)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;34m\"\"\" Call Java Function \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_java2py\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software_setup_for_hackathon\\spark\\python\\lib\\py4j-0.10.6-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1158\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1160\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software_setup_for_hackathon\\spark\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software_setup_for_hackathon\\spark\\python\\lib\\py4j-0.10.6-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    318\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    319\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    321\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o1746.corr.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 482.0 failed 1 times, most recent failure: Lost task 0.0 in stage 482.0 (TID 3025, localhost, executor driver): org.apache.spark.SparkException: Python worker did not connect back in time\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:143)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:72)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:117)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:86)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:135)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:404)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:199)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:138)\r\n\t... 15 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2027)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2048)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1358)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1331)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1372)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.first(RDD.scala:1371)\r\n\tat org.apache.spark.mllib.linalg.distributed.RowMatrix.numCols(RowMatrix.scala:61)\r\n\tat org.apache.spark.mllib.linalg.distributed.RowMatrix.computeCovariance(RowMatrix.scala:331)\r\n\tat org.apache.spark.mllib.stat.correlation.PearsonCorrelation$.computeCorrelationMatrix(PearsonCorrelation.scala:49)\r\n\tat org.apache.spark.mllib.stat.correlation.Correlations$.corrMatrix(Correlation.scala:66)\r\n\tat org.apache.spark.mllib.stat.Statistics$.corr(Statistics.scala:74)\r\n\tat org.apache.spark.mllib.api.python.PythonMLLibAPI.corr(PythonMLLibAPI.scala:846)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:483)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: org.apache.spark.SparkException: Python worker did not connect back in time\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:143)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:72)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:117)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:86)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:135)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:404)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:199)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:138)\r\n\t... 15 more\r\n"
     ]
    }
   ],
   "source": [
    "features = h_df2.rdd.map(lambda row: row[0:])\n",
    "\n",
    "from pyspark.mllib.stat import Statistics\n",
    "\n",
    "corr_mat=Statistics.corr(features, method=\"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.ml.stat.Correlation.corr.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 16.0 failed 1 times, most recent failure: Lost task 0.0 in stage 16.0 (TID 16, localhost, executor driver): org.apache.spark.SparkException: Python worker did not connect back in time\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:143)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:72)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:117)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:86)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:135)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:404)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:199)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:138)\r\n\t... 33 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2027)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2048)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1358)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1331)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1372)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.first(RDD.scala:1371)\r\n\tat org.apache.spark.mllib.linalg.distributed.RowMatrix.numCols(RowMatrix.scala:61)\r\n\tat org.apache.spark.mllib.linalg.distributed.RowMatrix.computeCovariance(RowMatrix.scala:331)\r\n\tat org.apache.spark.mllib.stat.correlation.PearsonCorrelation$.computeCorrelationMatrix(PearsonCorrelation.scala:49)\r\n\tat org.apache.spark.mllib.stat.correlation.Correlations$.corrMatrix(Correlation.scala:66)\r\n\tat org.apache.spark.mllib.stat.Statistics$.corr(Statistics.scala:74)\r\n\tat org.apache.spark.ml.stat.Correlation$.corr(Correlation.scala:73)\r\n\tat org.apache.spark.ml.stat.Correlation.corr(Correlation.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:483)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: org.apache.spark.SparkException: Python worker did not connect back in time\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:143)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:72)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:117)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:86)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:135)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:404)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:199)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:138)\r\n\t... 33 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-56e0ed055e56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"features\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mr1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCorrelation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"features\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Pearson correlation matrix:\\n\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software_setup_for_hackathon\\spark\\python\\pyspark\\ml\\stat.py\u001b[0m in \u001b[0;36mcorr\u001b[1;34m(dataset, column, method)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mjavaCorrObj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_jvm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCorrelation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_java2py\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjavaCorrObj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software_setup_for_hackathon\\spark\\python\\lib\\py4j-0.10.6-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1158\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1160\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software_setup_for_hackathon\\spark\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software_setup_for_hackathon\\spark\\python\\lib\\py4j-0.10.6-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    318\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    319\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    321\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.ml.stat.Correlation.corr.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 16.0 failed 1 times, most recent failure: Lost task 0.0 in stage 16.0 (TID 16, localhost, executor driver): org.apache.spark.SparkException: Python worker did not connect back in time\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:143)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:72)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:117)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:86)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:135)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:404)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:199)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:138)\r\n\t... 33 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2027)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2048)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1358)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1331)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1372)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.first(RDD.scala:1371)\r\n\tat org.apache.spark.mllib.linalg.distributed.RowMatrix.numCols(RowMatrix.scala:61)\r\n\tat org.apache.spark.mllib.linalg.distributed.RowMatrix.computeCovariance(RowMatrix.scala:331)\r\n\tat org.apache.spark.mllib.stat.correlation.PearsonCorrelation$.computeCorrelationMatrix(PearsonCorrelation.scala:49)\r\n\tat org.apache.spark.mllib.stat.correlation.Correlations$.corrMatrix(Correlation.scala:66)\r\n\tat org.apache.spark.mllib.stat.Statistics$.corr(Statistics.scala:74)\r\n\tat org.apache.spark.ml.stat.Correlation$.corr(Correlation.scala:73)\r\n\tat org.apache.spark.ml.stat.Correlation.corr(Correlation.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:483)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: org.apache.spark.SparkException: Python worker did not connect back in time\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:143)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:72)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:117)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:86)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:135)\r\n\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:404)\r\n\tat java.net.PlainSocketImpl.accept(PlainSocketImpl.java:199)\r\n\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\r\n\tat java.net.ServerSocket.accept(ServerSocket.java:513)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:138)\r\n\t... 33 more\r\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.stat import Correlation\n",
    "spark = SparkSession.builder.appName('correlation').getOrCreate()\n",
    "data = [(Vectors.sparse(4, [(0, 1.0), (3, -2.0)]),),\n",
    "        (Vectors.dense([4.0, 5.0, 0.0, 3.0]),),\n",
    "        (Vectors.dense([6.0, 7.0, 0.0, 8.0]),),\n",
    "        (Vectors.sparse(4, [(0, 9.0), (3, 1.0)]),)]\n",
    "df = spark.createDataFrame(data, [\"features\"])\n",
    "\n",
    "r1 = Correlation.corr(df, \"features\").head()\n",
    "print(\"Pearson correlation matrix:\\n\" + str(r1[0]))\n",
    "\n",
    "r2 = Correlation.corr(df, \"features\", \"spearman\").head()\n",
    "print(\"Spearman correlation matrix:\\n\" + str(r2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_rdd=h_df2.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1=data_train_rdd.map(lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2=data_train_rdd.map(lambda x:x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.stat import Statistics\n",
    "NewVector=data_train_rdd.map(lambda x:x[1:2]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# correlation_matrix = Statistics.corr(NewVector, method=\"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
