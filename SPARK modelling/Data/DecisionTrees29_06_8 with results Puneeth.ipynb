{"nbformat_minor": 2, "cells": [{"execution_count": 6, "cell_type": "code", "source": "#               TEST cluster to bring up the cluster session\na=2", "outputs": [{"output_type": "stream", "name": "stderr", "text": "An error was encountered:\nSession 8 did not reach idle status in time. Current status is busy.\n"}], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "#https://spark.apache.org/docs/2.1.0/ml-classification-regression.html#decision-tree-classifier", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 2, "cell_type": "code", "source": "from pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 3, "cell_type": "code", "source": "from pyspark.ml.feature import OneHotEncoder", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 5, "cell_type": "code", "source": "###              Import all the datasets from Azure Storage Container\n\ncustomerdetails = spark.read.csv(\"wasb://hackathonspark-2018-06-20t07-09-42-165z@hackathonspark.blob.core.windows.net/puneeth_delete/customerdetails.csv\", header=True, inferSchema=True)\ncustomer_cdr = spark.read.csv('wasb://hackathonspark-2018-06-20t07-09-42-165z@hackathonspark.blob.core.windows.net/puneeth_delete/customer_cdr.csv',header=True,inferSchema=True)\nplan_details = spark.read.csv('wasb://hackathonspark-2018-06-20t07-09-42-165z@hackathonspark.blob.core.windows.net/puneeth_delete/plan_details.csv',header=True,inferSchema=True)", "outputs": [{"output_type": "stream", "name": "stderr", "text": "An error was encountered:\nSession 8 did not reach idle status in time. Current status is busy.\n"}], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "##                         JOIN THE DATASETS INTO A SINGLE DATAFRAME\ndata = customer_details.join(customer_cdr,\"customer_unique_id\").join(plan_details,\"customer_unique_id\").join(signal_details, \"customer_unique_id\")", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "#                              DATA PREPRCOCESSING ", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "#Replace NAN with 0 calls.\ndata['customer_service_calls'].fillna(0, inplace=True)\ndata['international_plan'].fillna('no', inplace=True)\ndata['voice_mail_plan'].fillna('no', inplace=True)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 5, "cell_type": "code", "source": "cols = data.columns", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 6, "cell_type": "code", "source": "#                               count rows in DATA\ndata.count()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "3333"}], "metadata": {"collapsed": false}}, {"execution_count": 7, "cell_type": "code", "source": "#                                check column data types \ndata.dtypes", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[('state', 'string'), ('account_length', 'int'), ('area_code', 'int'), ('phone_number', 'string'), ('international_plan', 'string'), ('voice_mail_plan', 'string'), ('number_vmail_messages', 'int'), ('total_day_minutes', 'double'), ('total_day_calls', 'int'), ('total_day_charge', 'double'), ('total_eve_minutes', 'double'), ('total_eve_calls', 'int'), ('total_eve_charge', 'double'), ('total_night_minutes', 'double'), ('total_night_calls', 'int'), ('total_night_charge', 'double'), ('total_intl_minutes', 'double'), ('total_intl_calls', 'int'), ('total_intl_charge', 'double'), ('customer_service_calls', 'int'), ('churn', 'string')]"}], "metadata": {"collapsed": false}}, {"execution_count": 8, "cell_type": "code", "source": "categoricalColumns = ['state','phone_number','international_plan','voice_mail_plan']", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 9, "cell_type": "code", "source": "stages = [] # stages in our Pipeline\nstringIndexer = StringIndexer(inputCol='state', outputCol='stateIndex')\nencoder = OneHotEncoder(inputCol='stateIndex', outputCol='stateclassVec')\nstages += [stringIndexer, encoder]\nstringIndexer = StringIndexer(inputCol='phone_number', outputCol='phone_numberIndex')\nencoder = OneHotEncoder(inputCol='phone_numberIndex', outputCol='phone_numberclassVec')\nstages += [stringIndexer, encoder]\nstringIndexer = StringIndexer(inputCol='international_plan', outputCol='international_planIndex')\nencoder = OneHotEncoder(inputCol='international_planIndex', outputCol='international_planclassVec')\nstages += [stringIndexer, encoder]\nstringIndexer = StringIndexer(inputCol='voice_mail_plan', outputCol='voice_mail_planIndex')\nencoder = OneHotEncoder(inputCol='voice_mail_planIndex', outputCol='voice_mail_planclassVec')\nstages += [stringIndexer, encoder]", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 10, "cell_type": "code", "source": "label_stringIdx = StringIndexer(inputCol=\"churn\", outputCol=\"label\")\nstages += [label_stringIdx]", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 11, "cell_type": "code", "source": "numericCols = ['account_length','area_code','number_vmail_messages','total_day_minutes','total_day_calls','total_day_charge','total_eve_minutes','total_eve_calls','total_eve_charge','total_night_minutes','total_night_calls','total_night_charge','total_intl_minutes','total_intl_calls','total_intl_charge','customer_service_calls']     ", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 12, "cell_type": "code", "source": "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\nassembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\nstages += [assembler]", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 13, "cell_type": "code", "source": "pipeline = Pipeline(stages=stages)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 14, "cell_type": "code", "source": "pipelineModel = pipeline.fit(data)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 15, "cell_type": "code", "source": "data = pipelineModel.transform(data)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 16, "cell_type": "code", "source": "data.columns#", "outputs": [{"output_type": "stream", "name": "stdout", "text": "['state', 'account_length', 'area_code', 'phone_number', 'international_plan', 'voice_mail_plan', 'number_vmail_messages', 'total_day_minutes', 'total_day_calls', 'total_day_charge', 'total_eve_minutes', 'total_eve_calls', 'total_eve_charge', 'total_night_minutes', 'total_night_calls', 'total_night_charge', 'total_intl_minutes', 'total_intl_calls', 'total_intl_charge', 'customer_service_calls', 'churn', 'stateIndex', 'stateclassVec', 'phone_numberIndex', 'phone_numberclassVec', 'international_planIndex', 'international_planclassVec', 'voice_mail_planIndex', 'voice_mail_planclassVec', 'label', 'features']"}], "metadata": {"collapsed": false}}, {"execution_count": 17, "cell_type": "code", "source": "selectedcols = [\"label\", \"features\"] + cols\ndata = data.select(selectedcols)\n#display(data)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 18, "cell_type": "code", "source": "### Randomly split data into training and test sets. set seed for reproducibility\n(trainingData, testData) = data.randomSplit([0.7, 0.3], seed=100)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 19, "cell_type": "code", "source": "############################################## LOGISTIC REGRESSION", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 20, "cell_type": "code", "source": "from pyspark.ml.classification import LogisticRegression\n\n# Create initial LogisticRegression model\nlr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n\n# Train model with Training Data\nlrModel = lr.fit(trainingData)", "outputs": [], "metadata": {"scrolled": true, "collapsed": false}}, {"execution_count": 21, "cell_type": "code", "source": "predictions = lrModel.transform(testData)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "predictions.printSchema()", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "testData.count()\n", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "130+849+10+2", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "testData.filter(testData.churn=='Yes').count()", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "testData.filter(testData.churn=='No').count()", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 22, "cell_type": "code", "source": "# df.stat.crosstab(\"name\", \"item\").show()\n# When Churn= 'No' label= 0.0, most frequently occuring item is assigned 0.0\n# When Churn= 'Yes' label= 1.0\n\n# Prediction = 0.0  churn = No\n# Prediction = 1.0  churn = Yes\npredictions.stat.crosstab(\"label\",\"prediction\").show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+----------------+---+---+\n|label_prediction|0.0|1.0|\n+----------------+---+---+\n|             1.0|130| 10|\n|             0.0|849|  2|\n+----------------+---+---+"}], "metadata": {"scrolled": true, "collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "selected = predictions.select(\"label\", \"prediction\", \"state\")\n#display(selected)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "type(predictions)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "predictions.count()", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "predictions.columns", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "#predictions.write.csv('wasb://hackpyspark-2018-06-21t05-44-31-166z@lyoltv4o2zxni.blob.core.windows.net/puneeth_delete/trial_written.csv')", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "predictions.dtypes", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "records = predictions.filter(~predictions.churn.isin('Yes'))\n#records = predictions.filter(~predictions.churn.isin('No'))", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "records.take(2)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 23, "cell_type": "code", "source": "#to evaluate the model using area under the ROC curve\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Evaluate model\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\nevaluator.evaluate(predictions)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "0.7757680040288712"}], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "evaluator.getMetricName()", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 24, "cell_type": "code", "source": "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\n# Create ParamGrid for Cross Validation\nparamGrid = (ParamGridBuilder()\n             .addGrid(lr.regParam, [0.01, 0.5, 2.0])\n             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n             .addGrid(lr.maxIter, [1, 5, 10])\n             .build())", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 25, "cell_type": "code", "source": "# Create 5-fold CrossValidator\ncv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n\n# Run cross validations\ncvModel = cv.fit(trainingData)\n# this will likely take a fair amount of time because of the amount of models that we're creating and testing", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 26, "cell_type": "code", "source": "# Use test set to measure the accuracy of our model on new data\npredictions = cvModel.transform(testData)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 27, "cell_type": "code", "source": "# cvModel uses the best model found from the Cross Validation\n# Evaluate best model\nevaluator.evaluate(predictions)\n", "outputs": [{"output_type": "stream", "name": "stdout", "text": "0.8230653013261753"}], "metadata": {"collapsed": false}}, {"execution_count": 28, "cell_type": "code", "source": "# df.stat.crosstab(\"name\", \"item\").show()\n# When Churn= 'No' label= 0.0, most frequently occuring item is assigned 0.0\n# When Churn= 'Yes' label= 1.0\n\n# Prediction = 0.0  churn = No\n# Prediction = 1.0  churn = Yes\npredictions.stat.crosstab(\"label\",\"prediction\").show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+----------------+---+---+\n|label_prediction|0.0|1.0|\n+----------------+---+---+\n|             1.0|139|  1|\n|             0.0|850|  1|\n+----------------+---+---+"}], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "############################################## DECISION TREES", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 29, "cell_type": "code", "source": "from pyspark.ml.classification import DecisionTreeClassifier\n\n# Create initial Decision Tree Model\ndt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=3)\n\n# Train model with Training Data\ndtModel = dt.fit(trainingData)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "print(\"numNodes = \", dtModel.numNodes)\nprint(\"depth = \", dtModel.depth)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 30, "cell_type": "code", "source": "# Make predictions on test data using the Transformer.transform() method.\npredictions = dtModel.transform(testData)\n", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "predictions.printSchema()", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 31, "cell_type": "code", "source": "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n# Evaluate model\nevaluator = BinaryClassificationEvaluator()\nevaluator.evaluate(predictions)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "0.20144367970454927"}], "metadata": {"collapsed": false}}, {"execution_count": 32, "cell_type": "code", "source": "# df.stat.crosstab(\"name\", \"item\").show()\n# When Churn= 'No' label= 0.0, most frequently occuring item is assigned 0.0\n# When Churn= 'Yes' label= 1.0\n\n# Prediction = 0.0  churn = No\n# Prediction = 1.0  churn = Yes\npredictions.stat.crosstab(\"label\",\"prediction\").show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+----------------+---+---+\n|label_prediction|0.0|1.0|\n+----------------+---+---+\n|             1.0| 88| 52|\n|             0.0|844|  7|\n+----------------+---+---+"}], "metadata": {"collapsed": false}}, {"execution_count": 33, "cell_type": "code", "source": "# Create ParamGrid for Cross Validation\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nparamGrid = (ParamGridBuilder()\n             .addGrid(dt.maxDepth, [1, 2, 6, 10])\n             .addGrid(dt.maxBins, [20, 40, 80])\n             .build())", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 34, "cell_type": "code", "source": "# Create 5-fold CrossValidator\ncv = CrossValidator(estimator=dt, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n\n# Run cross validations\ncvModel = cv.fit(trainingData)\n# Takes ~5 minutes", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "print(\"numNodes = \", cvModel.bestModel.numNodes)\nprint(\"depth = \", cvModel.bestModel.depth)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 35, "cell_type": "code", "source": "# Use test set to measure the accuracy of our model on new data\npredictions = cvModel.transform(testData)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 36, "cell_type": "code", "source": "# cvModel uses the best model found from the Cross Validation\n# Evaluate best model\nevaluator.evaluate(predictions)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "0.4834102736276649"}], "metadata": {"collapsed": false}}, {"execution_count": 37, "cell_type": "code", "source": "# df.stat.crosstab(\"name\", \"item\").show()\n# When Churn= 'No' label= 0.0, most frequently occuring item is assigned 0.0\n# When Churn= 'Yes' label= 1.0\n\n# Prediction = 0.0  churn = No\n# Prediction = 1.0  churn = Yes\npredictions.stat.crosstab(\"label\",\"prediction\").show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+----------------+---+---+\n|label_prediction|0.0|1.0|\n+----------------+---+---+\n|             1.0| 39|101|\n|             0.0|841| 10|\n+----------------+---+---+"}], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "# View Best model's predictions and probabilities of each prediction class\nselected = predictions.select(\"label\", \"prediction\",\"state\")\ndisplay(selected)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "#####################################################  RANDOM FORREST", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 38, "cell_type": "code", "source": "from pyspark.ml.classification import RandomForestClassifier\n\n# Create an initial RandomForest model.\nrf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n\n# Train model with Training Data\nrfModel = rf.fit(trainingData)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 39, "cell_type": "code", "source": "# Make predictions on test data using the Transformer.transform() method.\npredictions = rfModel.transform(testData)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "predictions.printSchema()", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "# View model's predictions and probabilities of each prediction class\nselected = predictions.select(\"label\", \"state\")\ndisplay(selected)\n", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 40, "cell_type": "code", "source": "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Evaluate model\nevaluator = BinaryClassificationEvaluator()\nevaluator.evaluate(predictions)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "0.8443218062783273"}], "metadata": {"collapsed": false}}, {"execution_count": 41, "cell_type": "code", "source": "# df.stat.crosstab(\"name\", \"item\").show()\n# When Churn= 'No' label= 0.0, most frequently occuring item is assigned 0.0\n# When Churn= 'Yes' label= 1.0\n\n# Prediction = 0.0  churn = No\n# Prediction = 1.0  churn = Yes\npredictions.stat.crosstab(\"label\",\"prediction\").show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+----------------+---+\n|label_prediction|0.0|\n+----------------+---+\n|             1.0|140|\n|             0.0|851|\n+----------------+---+"}], "metadata": {"collapsed": false}}, {"execution_count": 42, "cell_type": "code", "source": "# Create ParamGrid for Cross Validation\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\nparamGrid = (ParamGridBuilder()\n             .addGrid(rf.maxDepth, [2, 4, 6])\n             .addGrid(rf.maxBins, [20, 60])\n             .addGrid(rf.numTrees, [5, 20])\n             .build())", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 43, "cell_type": "code", "source": "# Create 5-fold CrossValidator\ncv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n\n# Run cross validations.  This can take about 6 minutes since it is training over 20 trees!\ncvModel = cv.fit(trainingData)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 44, "cell_type": "code", "source": "# Use test set here so we can measure the accuracy of our model on new data\npredictions = cvModel.transform(testData)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 45, "cell_type": "code", "source": "# cvModel uses the best model found from the Cross Validation\n# Evaluate best model\nevaluator.evaluate(predictions)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "0.8173115662246083"}], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "# View Best model's predictions and probabilities of each prediction class\nselected = predictions.select(\"label\", \"state\")\ndisplay(selected)\n", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 46, "cell_type": "code", "source": "# df.stat.crosstab(\"name\", \"item\").show()\n# When Churn= 'No' label= 0.0, most frequently occuring item is assigned 0.0\n# When Churn= 'Yes' label= 1.0\n\n# Prediction = 0.0  churn = No\n# Prediction = 1.0  churn = Yes\npredictions.stat.crosstab(\"label\",\"prediction\").show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+----------------+---+\n|label_prediction|0.0|\n+----------------+---+\n|             1.0|140|\n|             0.0|851|\n+----------------+---+"}], "metadata": {"collapsed": false}}, {"execution_count": 49, "cell_type": "code", "source": "#distribution of test and traindata\ntrainingData.stat.crosstab(\"churn\",\"churn\").show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-----------+----+---+\n|churn_churn|  No|Yes|\n+-----------+----+---+\n|         No|1999|  0|\n|        Yes|   0|343|\n+-----------+----+---+"}], "metadata": {"collapsed": false}}, {"execution_count": 50, "cell_type": "code", "source": "1999+343", "outputs": [{"output_type": "stream", "name": "stdout", "text": "2342"}], "metadata": {"collapsed": false}}, {"execution_count": 51, "cell_type": "code", "source": "testData.stat.crosstab(\"churn\",\"churn\").show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-----------+---+---+\n|churn_churn| No|Yes|\n+-----------+---+---+\n|         No|851|  0|\n|        Yes|  0|140|\n+-----------+---+---+"}], "metadata": {"collapsed": false}}, {"execution_count": 52, "cell_type": "code", "source": "851+140", "outputs": [{"output_type": "stream", "name": "stdout", "text": "991"}], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "#####################################################################################################\n##https://docs.databricks.com/spark/latest/mllib/binary-classification-mllib-pipelines.html\n##    ##        ##        #####  ##   ##     ## ########################################################################################\n##    ##       ###      ###      ##  ##     #### #######################################################################################\n########      ## ##    ###       ## ##     ###### ###############################################################################\n########     #######   ###       ####     ######## ###########################################################################\n##    ##    ##     ##    ###     ## ##   ##      ## ###########################################################################\n##    ##   ##       ##    #####  ##  ## ##        ## #####################################################################\n\n#####################################################################################################\n#####################################################################################################\n#####################################################################################################\n#####################################################################################################     START", "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark", "name": "pysparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python2", "name": "pyspark", "codemirror_mode": {"version": 2, "name": "python"}}}}