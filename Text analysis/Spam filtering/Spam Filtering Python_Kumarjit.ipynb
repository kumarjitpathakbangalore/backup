{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Filtering Using Naive Bays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\inkpathak\\Desktop\\Anuj Gupta\\enron1\n"
     ]
    }
   ],
   "source": [
    "print (os.getcwd()) # this helps to see currently which location the control exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\inkpathak\\\\Desktop\\\\Anuj Gupta\\\\enron1') # Provide the path here where all the folders of spam and ham mails are located"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally you may receive multiple text files on Enron dataset which needs to be merged and leveled for further analysis. We are going to create a data frame file containing two columns \n",
    "        Text -> This column would contain the text body of each mail\n",
    "        Class -> This column contains the lebel of whether the mail is 'spam' or 'ham'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_data = pd.DataFrame(columns = (\"Text\", \"Class\")) \n",
    "# creating a data-frame with two columns Text= the extracted texts from each mail and Class represents whether it is \"Spam\" and \"Ham\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for cla in glob.glob(\"dataset/*\"): # Here the folder name is data set in which there are two sub-folder \"Spam\" & \"Ham\"\n",
    "    clas = cla.split(os.sep)[1]    # We are splitting the folder names as class using OS-Seperator and taking the 2nd item in the list\n",
    "    for file in glob.glob(cla + \"/*.txt\"): # Here we are deep diving in each of the folder and reading the text files one by one\n",
    "        text = open(file, \"r\", encoding = \"ISO-8859-1\").read() # Reading the file , for Windows generally we need to mention the encoding \n",
    "        text = \" \".join(text.split(\"\\n\")) # Splitting the text files and rejoining into a single text\n",
    "        spam_data = spam_data.append(pd.Series([text, clas], index = [\"Text\", \"Class\"]), ignore_index = True) # continious append to the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_data.to_csv('./datasets/email_classification.csv',index=False,header=True) # Writing the CSV file in to the location mentioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reading data \n",
    "Location = r'C:\\Users\\inkpathak\\Desktop\\Anuj Gupta\\enron1\\email_classification.csv'\n",
    "df = pd.read_csv(Location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: christmas tree farm pictures</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: vastar resources , inc . gary , produ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: calpine daily gas nomination - calpin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: re : issue fyi - see note below - alr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: meter 7268 nov allocation fyi . - - -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Class\n",
       "0             Subject: christmas tree farm pictures       0\n",
       "1  Subject: vastar resources , inc . gary , produ...      0\n",
       "2  Subject: calpine daily gas nomination - calpin...      0\n",
       "3  Subject: re : issue fyi - see note below - alr...      0\n",
       "4  Subject: meter 7268 nov allocation fyi . - - -...      0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5172, 2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\inkpathak\\AppData\\Local\\Continuum\\anaconda2\\envs\\py34t\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import Counter\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "from sklearn.metrics import confusion_matrix \n",
    "# Create a dictionary of words with its frequency\n",
    "import os\n",
    "import numpy as np \n",
    "import scipy as sp \n",
    "import matplotlib as mpl \n",
    "import matplotlib.cm as cm \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import nltk\n",
    "import re\n",
    "import csv\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert label to a numerical variable\n",
    "spam_data['Class'] = spam_data.Class.map({'ham':0, 'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_complete = spam_data['Text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5172"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spam_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Subject: vastar resources , inc . gary , production from the high island larger block a - 1 # 2 commenced on saturday at 2 : 00 p . m . at about 6 , 500 gross . carlos expects between 9 , 500 and 10 , 000 gross for tomorrow . vastar owns 68 % of the gross production . george x 3 - 6992 - - - - - - - - - - - - - - - - - - - - - - forwarded by george weissman / hou / ect on 12 / 13 / 99 10 : 16 am - - - - - - - - - - - - - - - - - - - - - - - - - - - daren j farmer 12 / 10 / 99 10 : 38 am to : carlos j rodriguez / hou / ect @ ect cc : george weissman / hou / ect @ ect , melissa graves / hou / ect @ ect subject : vastar resources , inc . carlos , please call linda and get everything set up . i \\' m going to estimate 4 , 500 coming up tomorrow , with a 2 , 000 increase each following day based on my conversations with bill fischer at bmar . d . - - - - - - - - - - - - - - - - - - - - - - forwarded by daren j farmer / hou / ect on 12 / 10 / 99 10 : 34 am - - - - - - - - - - - - - - - - - - - - - - - - - - - enron north america corp . from : george weissman 12 / 10 / 99 10 : 00 am to : daren j farmer / hou / ect @ ect cc : gary bryan / hou / ect @ ect , melissa graves / hou / ect @ ect subject : vastar resources , inc . darren , the attached appears to be a nomination from vastar resources , inc . for the high island larger block a - 1 # 2 ( previously , erroneously referred to as the # 1 well ) . vastar now expects the well to commence production sometime tomorrow . i told linda harris that we \\' d get her a telephone number in gas control so she can provide notification of the turn - on tomorrow . linda \\' s numbers , for the record , are 281 . 584 . 3359 voice and 713 . 312 . 1689 fax . would you please see that someone contacts linda and advises her how to submit future nominations via e - mail , fax or voice ? thanks . george x 3 - 6992 - - - - - - - - - - - - - - - - - - - - - - forwarded by george weissman / hou / ect on 12 / 10 / 99 09 : 44 am - - - - - - - - - - - - - - - - - - - - - - - - - - - \" linda harris \" on 12 / 10 / 99 09 : 38 : 43 am to : george weissman / hou / ect @ ect cc : subject : hi a - 1 # 2 effective 12 - 11 - 99 | - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - | | | | | | mscf / d | min ftp | time | | | | | | - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - | | | | | | 4 , 500 | 9 , 925 | 24 hours | | | | | | - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - | | | | | | 6 , 000 | 9 , 908 | 24 hours | | | | | | - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - | | | | | | 8 , 000 | 9 , 878 | 24 hours | | | | | | - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - | | | | | | 10 , 000 | 9 , 840 | 24 hours | | | | | | - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - | | | | | | 12 , 000 | 9 , 793 | 24 hours | | | | | | - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - | | | | | | 14 , 000 | 9 , 738 | 24 hours | | | | | | - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - | | | | | | 16 , 000 | 9 , 674 | 24 hours | | | | | | - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - | | | | | | 18 , 000 | 9 , 602 | 24 hours | | | | | | - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - | | | | | | 20 , 000 | 9 , 521 | 24 hours | | | | | | - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - | | | | | | 22 , 000 | 9 , 431 | 24 hours | | | | | | - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - | | | | | | 24 , 000 | 9 , 332 | 24 hours | | | | | | - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - | | | | | | 26 , 000 | 9 , 224 | 24 hours | | | | | | - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - | | | | | | 28 , 000 | 9 , 108 | 24 hours | | | | | | - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - | | | | | | 30 , 000 | 8 , 982 | 24 hours | | | | | | - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - | | | | | | 32 , 000 | 8 , 847 | 24 hours | | | | | | - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - | | | | | | 34 , 000 | 8 , 703 | 24 hours | | | | | | - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - | | | | | | 36 , 000 | 8 , 549 | 24 hours | | | | | | - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - |'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_complete[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(doc):\n",
    "    doc = \" \".join([i.replace('*', '') for i in doc.lower().split()])\n",
    "    doc = \" \".join([i.replace(':', ' ') for i in doc.split()])\n",
    "    doc = \" \".join([i.replace('.', ' ') for i in doc.split()])\n",
    "    doc = \" \".join([i.replace('=', '') for i in doc.split()])\n",
    "    doc = \" \".join([i.replace('/', ' ') for i in doc.split()])\n",
    "    doc = \" \".join([i.replace(')', ' ') for i in doc.split()])\n",
    "    doc = \" \".join([i.replace('(', ' ') for i in doc.split()])\n",
    "    doc = \" \".join([i.replace('\"', ' ') for i in doc.split()])\n",
    "    doc = \" \".join([i.replace('-', ' ') for i in doc.split()])\n",
    "    doc = \" \".join([i.replace('_', ' ') for i in doc.split()])\n",
    "    doc = \" \".join([i for i in doc.split() if not i.isdigit()])\n",
    "    doc = \" \".join([i for i in doc.split() if i.isalpha()])\n",
    "    doc = \" \".join([i for i in doc.split() if i not in stop])\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_clear = [clean(doc) for doc in spam_complete]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'subject duns number changes fyi forwarded gary l payne hou ect pm antoine v pierre pm tommy j yanowski hou ect ect kathryn bussell hou ect ect gary l payne hou ect ect diane e niestrath hou ect ect romeo souza hou ect ect michael eiben hou ect ect clem cernosek hou ect ect scotty gilbert hou ect ect dave nommensen hou ect ect david rohan hou ect ect kevin heal cal ect ect richard pinion hou ect ect cc mary g gosnell hou ect ect jason moore hou ect ect samuel schott hou ect ect bernice rodriguez hou ect ect subject duns number changes making changes wednesday december agree problem dnb number change please notify otherwise make change scheduled dunns number change counterparty cp id number cinergy resources inc energy dynamics management inc south jersey resources group llc transalta energy marketing us inc philadelphia gas works thanks rennie'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_clear[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(doc_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_data[\"clean_text\"] = spam_clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: christmas tree farm pictures</td>\n",
       "      <td>0</td>\n",
       "      <td>subject christmas tree farm pictures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: vastar resources , inc . gary , produ...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject vastar resources inc gary production h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: calpine daily gas nomination - calpin...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject calpine daily gas nomination calpine d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: re : issue fyi - see note below - alr...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject issue fyi see note already done stella...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: meter 7268 nov allocation fyi . - - -...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject meter nov allocation fyi forwarded lau...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Class  \\\n",
       "0             Subject: christmas tree farm pictures       0   \n",
       "1  Subject: vastar resources , inc . gary , produ...      0   \n",
       "2  Subject: calpine daily gas nomination - calpin...      0   \n",
       "3  Subject: re : issue fyi - see note below - alr...      0   \n",
       "4  Subject: meter 7268 nov allocation fyi . - - -...      0   \n",
       "\n",
       "                                          clean_text  \n",
       "0               subject christmas tree farm pictures  \n",
       "1  subject vastar resources inc gary production h...  \n",
       "2  subject calpine daily gas nomination calpine d...  \n",
       "3  subject issue fyi see note already done stella...  \n",
       "4  subject meter nov allocation fyi forwarded lau...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_data_ABT=spam_data[[\"Class\",\"clean_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>subject christmas tree farm pictures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>subject vastar resources inc gary production h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>subject calpine daily gas nomination calpine d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>subject issue fyi see note already done stella...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>subject meter nov allocation fyi forwarded lau...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class                                         clean_text\n",
       "0      0               subject christmas tree farm pictures\n",
       "1      0  subject vastar resources inc gary production h...\n",
       "2      0  subject calpine daily gas nomination calpine d...\n",
       "3      0  subject issue fyi see note already done stella...\n",
       "4      0  subject meter nov allocation fyi forwarded lau..."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data_ABT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5172,)\n",
      "(5172,)\n"
     ]
    }
   ],
   "source": [
    "# how to define X and y (from the mail spam data) for use with COUNTVECTORIZER\n",
    "X = spam_data_ABT.clean_text\n",
    "y = spam_data_ABT.Class\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3879,)\n",
      "(1293,)\n",
      "(3879,)\n",
      "(1293,)\n"
     ]
    }
   ],
   "source": [
    "# split X and y into training and testing sets\n",
    "# by default, it splits 75% training and 25% test\n",
    "# random_state=1 for reproducibility\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorizing our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. instantiate the vectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# learn training data vocabulary, then use it to create a document-term matrix\n",
    "\n",
    "# 3. fit\n",
    "vect.fit(X_train)\n",
    "\n",
    "# 4. transform training data\n",
    "X_train_dtm = vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# equivalently: combine fit and transform into a single step\n",
    "# this is faster and what most people would do\n",
    "X_train_dtm = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3879x39159 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 242859 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the document-term matrix\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1293x39159 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 70412 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm\n",
    "\n",
    "# you can see that the number of columns, 7456, is the same as what we have learned above in X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. import\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# 2. instantiate a Multinomial Naive Bayes model\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. train the model \n",
    "# using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "\n",
    "%time nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4. make class predictions for X_test_dtm\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9775715390564579"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    921\n",
      "1    372\n",
      "Name: Class, dtype: int64\n",
      "Null accuracy: 0    0.712297\n",
      "Name: Class, dtype: float64\n",
      "Manual null accuracy: 0.8671931083991385\n"
     ]
    }
   ],
   "source": [
    "# examine class distribution\n",
    "print(y_test.value_counts())\n",
    "# there is a majority class of 0 here, hence the classes are skewed\n",
    "\n",
    "# calculate null accuracy (for multi-class classification problems)\n",
    "# .head(1) assesses the value 1208\n",
    "null_accuracy = y_test.value_counts().head(1) / len(y_test)\n",
    "print('Null accuracy:', null_accuracy)\n",
    "\n",
    "# Manual calculation of null accuracy by always predicting the majority class\n",
    "print('Manual null accuracy:',(1208 / (1208 + 185)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[911,  10],\n",
       "       [ 19, 353]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3597    subject important video announcement important...\n",
       "3539    subject dear wish find mission kosovo find new...\n",
       "2456    subject hunter singing christmas program video...\n",
       "126     subject fw quips remember amateurs built ark p...\n",
       "2068    subject skydive spaceland specials skydive spa...\n",
       "301     subject expatriate zone issue expatriate zone ...\n",
       "2772    subject boat believe boat ft long boat cover b...\n",
       "2479    subject weekly fan fares delta fan fares febru...\n",
       "304     subject http www pge texas com www gtt nsf htm...\n",
       "107     subject new email yo bro new email address sav...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print message text for the false positives (ham incorrectly classified as spam)\n",
    "\n",
    "X_test[y_pred_class > y_test]\n",
    "\n",
    "# alternative less elegant but easier to understand\n",
    "# X_test[(y_pred_class==1) & (y_test==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3835                 subject multiple ways get home loans\n",
       "3789                                              subject\n",
       "4932    subject hello mail transaction failed partial ...\n",
       "3743                              subject holiday e cards\n",
       "4728                                              subject\n",
       "4423                                        subject enjoy\n",
       "5168          subject str rndlen extra time word bodyhtml\n",
       "4646    subject investigation tue jan sir trouble gett...\n",
       "4657                               subject hi try nothing\n",
       "3971    subject thu may first gove rnment mo rtgage pr...\n",
       "3830           subject document please read attached file\n",
       "3815    subject feeling slze johnson rtxyj nxfgr ktrqr...\n",
       "4181    subject network wed aug kttihkefi iewmeh ckust...\n",
       "4684                                              subject\n",
       "4830                                         subject note\n",
       "4498    subject promised help people please refer ques...\n",
       "3748                    subject holiday e cards gbhzivjwl\n",
       "4593                                              subject\n",
       "4254                                              subject\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print message text for the false negatives (spam incorrectly classified as ham)\n",
    "\n",
    "X_test[y_pred_class < y_test]\n",
    "# alternative less elegant but easier to understand\n",
    "# X_test[(y_pred_class=0) & (y_test=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.08465903e-022, 8.98003374e-030, 2.86781696e-043, ...,\n",
       "       2.19034125e-009, 7.51472506e-027, 1.85378583e-113])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities for X_test_dtm (poorly calibrated)\n",
    "\n",
    "# Numpy Array with 2C\n",
    "# left Column: probability class 0\n",
    "# right C: probability class 1\n",
    "# we only need the right column \n",
    "y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob\n",
    "\n",
    "# Naive Bayes predicts very extreme probabilites, you should not take them at face value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9966405146346304"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate AUC\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. import\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 2. instantiate a logistic regression model\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 575 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. train the model using X_train_dtm\n",
    "%time logreg.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4. make class predictions for X_test_dtm\n",
    "y_pred_class = logreg.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.07731912e-05, 3.21678236e-03, 1.67163834e-05, ...,\n",
       "       2.88866399e-03, 1.10065759e-04, 1.19296726e-12])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities for X_test_dtm (well calibrated)\n",
    "y_pred_prob = logreg.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9791183294663574"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9967397522561965"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate AUC\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining a model for further insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39159"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the vocabulary of X_train\n",
    "X_train_tokens = vect.get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 39159)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows represent classes, columns represent tokens\n",
    "nb.feature_count_.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 1., 0., 0.])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times each token appears across all HAM messages\n",
    "ham_token_count = nb.feature_count_[0, :]\n",
    "ham_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.,  1.,  1., ...,  0.,  1.,  1.])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times each token appears across all SPAM messages\n",
    "spam_token_count = nb.feature_count_[1, :]\n",
    "spam_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaa</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aabvmmq</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aac</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aachecar</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ham  spam\n",
       "token              \n",
       "aa        1.0  15.0\n",
       "aaa       0.0   1.0\n",
       "aabvmmq   0.0   1.0\n",
       "aac       0.0   1.0\n",
       "aachecar  1.0   0.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame of tokens with their separate ham and spam counts\n",
    "tokens = pd.DataFrame({'token':X_train_tokens, 'ham':ham_token_count, 'spam':spam_token_count}).set_index('token')\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>additive</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseboard</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frazier</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesenteric</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ferc</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ham  spam\n",
       "token                 \n",
       "additive     0.0   1.0\n",
       "baseboard    0.0   2.0\n",
       "frazier      0.0   2.0\n",
       "mesenteric   0.0   1.0\n",
       "ferc        38.0   0.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine 5 random DataFrame rows\n",
    "# random_state=6 is a seed for reproducibility\n",
    "tokens.sample(5, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2751., 1128.])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes counts the number of observations in each class\n",
    "nb.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
