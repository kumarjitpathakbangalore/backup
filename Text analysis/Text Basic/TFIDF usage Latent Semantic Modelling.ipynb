{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading data \n",
    "Location = r'C:\\Users\\inkpathak\\Desktop\\KP way Text Basic\\Text Basic\\server text.csv'\n",
    "server_data = pd.read_csv(Location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Notes_clean</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04/02/2018 10:13:07</td>\n",
       "      <td>Use ADRCI or Support Workbench to package the ...</td>\n",
       "      <td>use adrci support workbench package incident s...</td>\n",
       "      <td>Dumping diagnostic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03/02/2018 06:13:34</td>\n",
       "      <td>Current log# 11 seq# 31124 mem# 0: +REDO_DG04/...</td>\n",
       "      <td>current merlp tp onlinelog group current merlp...</td>\n",
       "      <td>LGWR switch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03/02/2018 06:13:35</td>\n",
       "      <td>Archived Log entry 182454 added for thread 3 s...</td>\n",
       "      <td>archived log entry added thread sequence id dest</td>\n",
       "      <td>Archived Log entry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04/02/2018 20:13:06</td>\n",
       "      <td>Running KSFV I/O slave I601 os pid=24411</td>\n",
       "      <td>running ksfv slave os</td>\n",
       "      <td>KSFV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/02/2018 16:42:52</td>\n",
       "      <td>TNS-00505: Operation timed out.01/02/2018 16:4...</td>\n",
       "      <td>tns operation timed nt os err code client addr...</td>\n",
       "      <td>Fatal NI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date                                              Notes  \\\n",
       "0  04/02/2018 10:13:07  Use ADRCI or Support Workbench to package the ...   \n",
       "1  03/02/2018 06:13:34  Current log# 11 seq# 31124 mem# 0: +REDO_DG04/...   \n",
       "2  03/02/2018 06:13:35  Archived Log entry 182454 added for thread 3 s...   \n",
       "3  04/02/2018 20:13:06           Running KSFV I/O slave I601 os pid=24411   \n",
       "4  01/02/2018 16:42:52  TNS-00505: Operation timed out.01/02/2018 16:4...   \n",
       "\n",
       "                                         Notes_clean          Prediction  \n",
       "0  use adrci support workbench package incident s...  Dumping diagnostic  \n",
       "1  current merlp tp onlinelog group current merlp...         LGWR switch  \n",
       "2   archived log entry added thread sequence id dest  Archived Log entry  \n",
       "3                              running ksfv slave os                KSFV  \n",
       "4  tns operation timed nt os err code client addr...            Fatal NI  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is tokenizing ?\n",
    "\n",
    "Splitting a document based on it's word component is called tokenizing'\n",
    "\n",
    "How to convert tokenized bag of words into numbers \n",
    "    * Count vectorizer or to create Document Term Matrix  for each of the document how many timne each word has appeared ?\n",
    "    * TFIDF ---- will discuss in some time    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'current merlp tp onlinelog group current merlp tp onlinelog group thread advanced log sequence lgwr switch'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server_data['Notes_clean'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'use adrci support workbench package incident see note oracle support error packaging details dumping diagnostic data requested sweep completed'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server_data['Notes_clean'][0]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'errors file dborafiles admin diag rdbms merlp tp trace trc ora error auto execute job lu lu j default consumer ora queue sys lu messages q exist ora lu log util adm line ora line'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server_data['Notes_clean'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'archived log entry added thread sequence id dest current merlp tp onlinelog group thread advanced log sequence lgwr switch current merlp tp onlinelog group'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server_data['Notes_clean'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF example:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bowA=server_data['Notes_clean'][5]\n",
    "bowB=server_data['Notes_clean'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bowA=bowA.split(\" \")\n",
    "bowB=bowB.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['errors',\n",
       " 'file',\n",
       " 'dborafiles',\n",
       " 'admin',\n",
       " 'diag',\n",
       " 'rdbms',\n",
       " 'merlp',\n",
       " 'tp',\n",
       " 'trace',\n",
       " 'trc',\n",
       " 'ora',\n",
       " 'error',\n",
       " 'auto',\n",
       " 'execute',\n",
       " 'job',\n",
       " 'lu',\n",
       " 'lu',\n",
       " 'j',\n",
       " 'default',\n",
       " 'consumer',\n",
       " 'ora',\n",
       " 'queue',\n",
       " 'sys',\n",
       " 'lu',\n",
       " 'messages',\n",
       " 'q',\n",
       " 'exist',\n",
       " 'ora',\n",
       " 'lu',\n",
       " 'log',\n",
       " 'util',\n",
       " 'adm',\n",
       " 'line',\n",
       " 'ora',\n",
       " 'line']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bowA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSet = set(bowA).union(set(bowB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'added',\n",
       " 'adm',\n",
       " 'admin',\n",
       " 'advanced',\n",
       " 'archived',\n",
       " 'auto',\n",
       " 'consumer',\n",
       " 'current',\n",
       " 'dborafiles',\n",
       " 'default',\n",
       " 'dest',\n",
       " 'diag',\n",
       " 'entry',\n",
       " 'error',\n",
       " 'errors',\n",
       " 'execute',\n",
       " 'exist',\n",
       " 'file',\n",
       " 'group',\n",
       " 'id',\n",
       " 'j',\n",
       " 'job',\n",
       " 'lgwr',\n",
       " 'line',\n",
       " 'log',\n",
       " 'lu',\n",
       " 'merlp',\n",
       " 'messages',\n",
       " 'onlinelog',\n",
       " 'ora',\n",
       " 'q',\n",
       " 'queue',\n",
       " 'rdbms',\n",
       " 'sequence',\n",
       " 'switch',\n",
       " 'sys',\n",
       " 'thread',\n",
       " 'tp',\n",
       " 'trace',\n",
       " 'trc',\n",
       " 'util'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to keep the counts of the words\n",
    "wordDictA=dict.fromkeys(wordSet,0)\n",
    "wordDictB=dict.fromkeys(wordSet,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating DTM\n",
    "for word in bowA:\n",
    "    wordDictA[word]= 1+ wordDictA[word]\n",
    "for word in bowB:\n",
    "    wordDictA[word]= 1+ wordDictB[word]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>added</th>\n",
       "      <th>adm</th>\n",
       "      <th>admin</th>\n",
       "      <th>advanced</th>\n",
       "      <th>archived</th>\n",
       "      <th>auto</th>\n",
       "      <th>consumer</th>\n",
       "      <th>current</th>\n",
       "      <th>dborafiles</th>\n",
       "      <th>default</th>\n",
       "      <th>...</th>\n",
       "      <th>queue</th>\n",
       "      <th>rdbms</th>\n",
       "      <th>sequence</th>\n",
       "      <th>switch</th>\n",
       "      <th>sys</th>\n",
       "      <th>thread</th>\n",
       "      <th>tp</th>\n",
       "      <th>trace</th>\n",
       "      <th>trc</th>\n",
       "      <th>util</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   added  adm  admin  advanced  archived  auto  consumer  current  dborafiles  \\\n",
       "0      1    1      1         1         1     1         1        1           1   \n",
       "1      0    0      0         0         0     0         0        0           0   \n",
       "\n",
       "   default  ...   queue  rdbms  sequence  switch  sys  thread  tp  trace  trc  \\\n",
       "0        1  ...       1      1         1       1    1       1   1      1    1   \n",
       "1        0  ...       0      0         0       0    0       0   0      0    0   \n",
       "\n",
       "   util  \n",
       "0     1  \n",
       "1     0  \n",
       "\n",
       "[2 rows x 41 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([wordDictA,wordDictB])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Why DTM is not so good idea?\n",
    "\n",
    "    * First of all this is a discrete representation of the document and no symantics covered.\n",
    "    \n",
    "    * Most common words in the english langiage is \"the\" it consists of nearly 7% of the words we say. Next one is \"of\" which is nearly half of it.\n",
    "\n",
    "#### Distribution of words in any language is a power law distribution . this forms the basis for Zip's law"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why TFIDF is a better choice?\n",
    "\n",
    "TFIDF = TF(word)* IDF(word)\n",
    "    Where,\n",
    "    \n",
    "    TF(word1) = (number of times word appears in a document) / (Total number of words in the document)\n",
    "    \n",
    "    IDF(word1) = log [(number of documents)/(no of documents containing word1)]\n",
    "    \n",
    "so TFIDF has one added advantage of IDF which acts as relative importance for each words based on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TF(wordDict,bow):\n",
    "    tfDict={}\n",
    "    bowCount = len(bow)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word]=count/ float(bowCount)\n",
    "    return tfDict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfBowA=compute_TF(wordDictA,bowA)\n",
    "tfBowB=compute_TF(wordDictB,bowB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def compute_IDF(doclist):\n",
    "    idf_Dict= {}\n",
    "    N=len(docList)\n",
    "    \n",
    "    # lets count number of document proportion containing the selected word\n",
    "    idf_Dict = dict.fromkeys(docList[0].keys(),0)\n",
    "    for doc in docList:\n",
    "        for word, val in doc.items():\n",
    "            if val>0:\n",
    "                idf_Dict[word]= idf_Dict[word] + 1\n",
    "    \n",
    "    for word, val in idf_Dict.items():\n",
    "        idf_Dict[word]= math.log(N/float(val))\n",
    "    return idf_Dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "docList= [wordDictA,wordDictB]\n",
    "idfs= compute_IDF(docList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TFIDF(tfBow, idfs):\n",
    "    tfidf={}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word]= val * idfs[word]\n",
    "    return tfidf    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfBowA= compute_TFIDF(tfBowA,idfs)\n",
    "tfidfBowB= compute_TFIDF(tfBowB,idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>added</th>\n",
       "      <th>adm</th>\n",
       "      <th>admin</th>\n",
       "      <th>advanced</th>\n",
       "      <th>archived</th>\n",
       "      <th>auto</th>\n",
       "      <th>consumer</th>\n",
       "      <th>current</th>\n",
       "      <th>dborafiles</th>\n",
       "      <th>default</th>\n",
       "      <th>...</th>\n",
       "      <th>queue</th>\n",
       "      <th>rdbms</th>\n",
       "      <th>sequence</th>\n",
       "      <th>switch</th>\n",
       "      <th>sys</th>\n",
       "      <th>thread</th>\n",
       "      <th>tp</th>\n",
       "      <th>trace</th>\n",
       "      <th>trc</th>\n",
       "      <th>util</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.019804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      added       adm     admin  advanced  archived      auto  consumer  \\\n",
       "0  0.019804  0.019804  0.019804  0.019804  0.019804  0.019804  0.019804   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "    current  dborafiles   default    ...        queue     rdbms  sequence  \\\n",
       "0  0.019804    0.019804  0.019804    ...     0.019804  0.019804  0.019804   \n",
       "1  0.000000    0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "\n",
       "     switch       sys    thread        tp     trace       trc      util  \n",
       "0  0.019804  0.019804  0.019804  0.019804  0.019804  0.019804  0.019804  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[2 rows x 41 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([tfidfBowA,tfidfBowB])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we understand how TFIDF can be created , let implement the same in a Model with Latent feature calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['rec.sport.baseball']\n",
    "dataset = fetch_20newsgroups(subset='all',shuffle=True, random_state=42, categories=categories)\n",
    "corpus=dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\inkpathak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopset = set(stopwords.words('english'))\n",
    "stopset.update(['tp','trc',  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = server_data['Notes_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very important step of N-Gram as well\n",
    "vectorizer = TfidfVectorizer(stop_words=stopset,use_idf=True, ngram_range=(1, 3))\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x3679 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 53 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x3679 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 83 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Symantic Analysis (Topic scoring)\n",
    "\n",
    "input = X [matrix with \"M\" no of documents and \"N\" number of words]\n",
    "\n",
    "Process = Perdorm SVD ( Singular Value Decomposition for this input matrix) \n",
    "        X = U * S * V-Transpose\n",
    "   Where:\n",
    "   \n",
    "   U = M*K matrix --------------- Rows would be the document and columns will be concepts(K)\n",
    "   \n",
    "   S = K*K diagonal matrix ------ Elements would be the amount of variations captured from each concept(K)\n",
    "   \n",
    "   Vt = K*N matrix -------------- Rows will be concepts(K) and columns would be the terms---- Need to care for transpose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=45, n_iter=100,\n",
       "       random_state=None, tol=0.0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa = TruncatedSVD(n_components=45, n_iter=100)\n",
    "lsa.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.26372733e-07,   1.26372734e-07,   1.26372734e-07, ...,\n",
       "         1.49150842e-07,   1.49150842e-07,   1.49150842e-07])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lsa.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept 0:\n",
      "sequence\n",
      "thread\n",
      "added thread\n",
      "added thread sequence\n",
      "archived\n",
      "archived log\n",
      "archived log entry\n",
      "entry\n",
      "entry added\n",
      "entry added thread\n",
      " \n",
      "Concept 1:\n",
      "group\n",
      "onlinelog\n",
      "onlinelog group\n",
      "current\n",
      "current onlinelog\n",
      "current onlinelog group\n",
      "advanced\n",
      "advanced log\n",
      "advanced log sequence\n",
      "lgwr\n",
      " \n",
      "Concept 2:\n",
      "lu\n",
      "ora\n",
      "line\n",
      "adm\n",
      "adm line\n",
      "adm line ora\n",
      "consumer\n",
      "consumer ora\n",
      "consumer ora queue\n",
      "default consumer\n",
      " \n",
      "Concept 3:\n",
      "ksfv\n",
      "ksfv slave\n",
      "slave\n",
      "ksfv slave os\n",
      "running\n",
      "running ksfv\n",
      "running ksfv slave\n",
      "slave os\n",
      "os\n",
      "exiting\n",
      " \n",
      "Concept 4:\n",
      "sys\n",
      "sys sys\n",
      "sys sys sys\n",
      "index\n",
      "agg\n",
      "dly\n",
      "deleted\n",
      "deleted statistics\n",
      "statistics\n",
      "columns\n",
      " \n",
      "Concept 5:\n",
      "alter system archive\n",
      "archive\n",
      "archive log\n",
      "system archive\n",
      "system archive log\n",
      "alter\n",
      "alter system\n",
      "system\n",
      "log\n",
      "current merlp\n",
      " \n",
      "Concept 6:\n",
      "current merlp\n",
      "current merlp onlinelog\n",
      "merlp onlinelog\n",
      "merlp onlinelog group\n",
      "merlp\n",
      "group current merlp\n",
      "switch current merlp\n",
      "group archived\n",
      "group archived log\n",
      "onlinelog group archived\n",
      " \n",
      "Concept 7:\n",
      "exiting\n",
      "ksfv slave exiting\n",
      "slave exiting\n",
      "ksfv\n",
      "ksfv slave\n",
      "slave\n",
      "exiting ksfv\n",
      "exiting ksfv slave\n",
      "slave exiting ksfv\n",
      "exiting archived\n",
      " \n",
      "Concept 8:\n",
      "index\n",
      "index con\n",
      "index con dm\n",
      "index marked\n",
      "index marked unusable\n",
      "marked\n",
      "marked unusable\n",
      "unusable\n",
      "stg\n",
      "con\n",
      " \n",
      "Concept 9:\n",
      "background\n",
      "background process\n",
      "process\n",
      "auto tuning\n",
      "tuning\n",
      "code\n",
      "err\n",
      "err code\n",
      "auto tuning shutting\n",
      "shutting\n",
      " \n",
      "Concept 10:\n",
      "code\n",
      "err\n",
      "err code\n",
      "nt\n",
      "tns\n",
      "version\n",
      "linux version\n",
      "linux version production\n",
      "production\n",
      "version production\n",
      " \n",
      "Concept 11:\n",
      "il\n",
      "il edw\n",
      "index table int\n",
      "int\n",
      "int owner\n",
      "int owner il\n",
      "owner il\n",
      "owner il edw\n",
      "table int\n",
      "table int owner\n",
      " \n",
      "Concept 12:\n",
      "starting\n",
      "starting background\n",
      "starting background process\n",
      "started os\n",
      "auto tuning starting\n",
      "tuning starting\n",
      "tuning starting background\n",
      "started\n",
      "background process started\n",
      "process started\n",
      " \n",
      "Concept 13:\n",
      "rdbms trace ora\n",
      "diag rdbms trace\n",
      "rdbms trace\n",
      "dynamic\n",
      "dynamic sampling\n",
      "dynamic sampling time\n",
      "ora dynamic\n",
      "ora dynamic sampling\n",
      "sampling\n",
      "sampling time\n",
      " \n",
      "Concept 14:\n",
      "size\n",
      "completed\n",
      "completed old\n",
      "completed old size\n",
      "new size\n",
      "old size\n",
      "old size new\n",
      "operation completed\n",
      "operation completed old\n",
      "resize\n",
      " \n",
      "Concept 15:\n",
      "mc\n",
      "dm uw stg\n",
      "uw stg\n",
      "id index\n",
      "id index marked\n",
      "uw stg idx\n",
      "chnl\n",
      "idx mc\n",
      "stg idx mc\n",
      "view\n",
      " \n",
      "Concept 16:\n",
      "group thread advanced\n",
      "group thread\n",
      "onlinelog group thread\n",
      "dest current\n",
      "id dest current\n",
      "dest current merlp\n",
      "lgwr switch archived\n",
      "switch archived\n",
      "switch archived log\n",
      "current onlinelog\n",
      " \n",
      "Concept 17:\n",
      "aborting\n",
      "aborting process\n",
      "aborting process unknown\n",
      "opidcl\n",
      "opidcl aborting\n",
      "opidcl aborting process\n",
      "ospid\n",
      "ospid result\n",
      "ospid result ora\n",
      "process unknown\n",
      " \n",
      "Concept 18:\n",
      "nfs\n",
      "check permissions\n",
      "check permissions server\n",
      "direct\n",
      "direct nfs\n",
      "direct nfs please\n",
      "nfs please\n",
      "nfs please check\n",
      "nfs servers\n",
      "nfs servers require\n",
      " \n",
      "Concept 19:\n",
      "plan\n",
      "resource manager\n",
      "via\n",
      "manager\n",
      "resource\n",
      "via parameter\n",
      "parameter\n",
      "plan via\n",
      "manager plan\n",
      "resource manager plan\n",
      " \n",
      "Concept 20:\n",
      "deleted\n",
      "deleted statistics\n",
      "statistics\n",
      "columns\n",
      "deleted statistics columns\n",
      "statistics columns\n",
      "table\n",
      "mc\n",
      "dm mc\n",
      "table dm mc\n",
      " \n",
      "Concept 21:\n",
      "data requested\n",
      "diagnostic\n",
      "diagnostic data\n",
      "diagnostic data requested\n",
      "dumping\n",
      "dumping diagnostic\n",
      "dumping diagnostic data\n",
      "requested\n",
      "data\n",
      "data requested process\n",
      " \n",
      "Concept 22:\n",
      "transaction\n",
      "smon\n",
      "acquire skipping\n",
      "acquire skipping transaction\n",
      "failed acquire\n",
      "failed acquire skipping\n",
      "skipping\n",
      "skipping transaction\n",
      "smon failed\n",
      "smon failed acquire\n",
      " \n",
      "Concept 23:\n",
      "exiting ksfv\n",
      "exiting ksfv slave\n",
      "slave exiting ksfv\n",
      "ksfv slave os\n",
      "running\n",
      "running ksfv\n",
      "running ksfv slave\n",
      "slave os\n",
      "os\n",
      "os ksfv\n",
      " \n",
      "Concept 24:\n",
      "lgwr switch current\n",
      "switch current\n",
      "switch current onlinelog\n",
      "group archived\n",
      "group archived log\n",
      "onlinelog group archived\n",
      "group thread advanced\n",
      "group thread\n",
      "onlinelog group thread\n",
      "switch current merlp\n",
      " \n",
      "Concept 25:\n",
      "table dm\n",
      "dm\n",
      "dm mc\n",
      "table dm mc\n",
      "dl\n",
      "dm owner\n",
      "index table dm\n",
      "table dm owner\n",
      "dm mc programme\n",
      "mc programme\n",
      " \n",
      "Concept 26:\n",
      "daily\n",
      "daily mc\n",
      "table daily\n",
      "table daily mc\n",
      "sys table daily\n",
      "daily mc chnl\n",
      "index table\n",
      "indexes\n",
      "indexes index\n",
      "indexes index table\n",
      " \n",
      "Concept 27:\n",
      "parallel\n",
      "parallel transaction\n",
      "parallel transaction recovery\n",
      "recovery\n",
      "recovery tried\n",
      "smon parallel\n",
      "smon parallel transaction\n",
      "transaction recovery\n",
      "transaction recovery tried\n",
      "tried\n",
      " \n",
      "Concept 28:\n",
      "group archived\n",
      "group archived log\n",
      "onlinelog group archived\n",
      "dest thread\n",
      "dest thread advanced\n",
      "id dest thread\n",
      "switch current merlp\n",
      "group thread\n",
      "onlinelog group thread\n",
      "group thread advanced\n",
      " \n",
      "Concept 29:\n",
      "version\n",
      "linux version\n",
      "linux version production\n",
      "production\n",
      "version production\n",
      "linux\n",
      "adapter\n",
      "adapter linux\n",
      "adapter linux version\n",
      "nt protocol\n",
      " \n",
      "Concept 30:\n",
      "detach\n",
      "detach msg\n",
      "detach msg inst\n",
      "dom\n",
      "inst dom\n",
      "msg\n",
      "msg inst\n",
      "msg inst dom\n",
      "received\n",
      "received detach\n",
      " \n",
      "Concept 31:\n",
      "edw nrt\n",
      "edw nrt hourly\n",
      "hourly\n",
      "hourly agg\n",
      "index table queueview\n",
      "nrt\n",
      "nrt hourly\n",
      "nrt hourly agg\n",
      "owner edw nrt\n",
      "queueview\n",
      " \n",
      "Concept 32:\n",
      "usage agg\n",
      "mob usage agg\n",
      "mob usage\n",
      "sum\n",
      "agg sum\n",
      "dly mob\n",
      "dly mob usage\n",
      "table dly\n",
      "table dly mob\n",
      "usage agg sum\n",
      " \n",
      "Concept 33:\n",
      "dest current\n",
      "id dest current\n",
      "dest current merlp\n",
      "group archived\n",
      "group archived log\n",
      "onlinelog group archived\n",
      "group current onlinelog\n",
      "lgwr switch archived\n",
      "switch archived\n",
      "switch archived log\n",
      " \n",
      "Concept 34:\n",
      "writing\n",
      "writing trace\n",
      "writing trace file\n",
      "trace file\n",
      "connect string\n",
      "connect string could\n",
      "could\n",
      "could error\n",
      "ora connect\n",
      "ora connect string\n",
      " \n",
      "Concept 35:\n",
      "gcs\n",
      "gcs shadows\n",
      "gcs shadows xw\n",
      "lms\n",
      "lms gcs\n",
      "lms gcs shadows\n",
      "shadows\n",
      "shadows xw\n",
      "shadows xw survived\n",
      "survived\n",
      " \n",
      "Concept 36:\n",
      "edw propensity\n",
      "edw propensity master\n",
      "propensity\n",
      "propensity master\n",
      "table edw\n",
      "table edw propensity\n",
      "master\n",
      "master sys\n",
      "propensity master sys\n",
      "master sys sys\n",
      " \n",
      "Concept 37:\n",
      "connect string\n",
      "connect string could\n",
      "could\n",
      "could error\n",
      "ora connect\n",
      "ora connect string\n",
      "ora ora connect\n",
      "string\n",
      "string could\n",
      "string could error\n",
      " \n",
      "Concept 38:\n",
      "sweep\n",
      "sweep completed\n",
      "completed\n",
      "completed sweep\n",
      "completed sweep completed\n",
      "sweep completed sweep\n",
      "support\n",
      "details\n",
      "connect string\n",
      "connect string could\n",
      " \n",
      "Concept 39:\n",
      "mob\n",
      "base\n",
      "active base\n",
      "mob active\n",
      "mob active base\n",
      "active\n",
      "idx mobile\n",
      "idx mobile usage\n",
      "stg idx mobile\n",
      "mob stg pk\n",
      " \n",
      "Concept 40:\n",
      "default maintenance\n",
      "default maintenance plan\n",
      "maintenance\n",
      "maintenance plan\n",
      "plan default\n",
      "plan default maintenance\n",
      "setting\n",
      "setting resource\n",
      "setting resource manager\n",
      "manager plan default\n",
      " \n",
      "Concept 41:\n",
      "gcs shadows\n",
      "gcs shadows xw\n",
      "lms\n",
      "lms gcs\n",
      "lms gcs shadows\n",
      "shadows\n",
      "shadows xw\n",
      "shadows xw survived\n",
      "survived\n",
      "xw\n",
      " \n",
      "Concept 42:\n",
      "mc usage\n",
      "daily mc usage\n",
      "view\n",
      "mc usage view\n",
      "usage view\n",
      "sys sys deleted\n",
      "idx mc use\n",
      "mc use\n",
      "use\n",
      "sys deleted\n",
      " \n",
      "Concept 43:\n",
      "lgwr switch archived\n",
      "switch archived\n",
      "switch archived log\n",
      "dest thread\n",
      "dest thread advanced\n",
      "id dest thread\n",
      "switch current onlinelog\n",
      "group current merlp\n",
      "current onlinelog\n",
      "current onlinelog group\n",
      " \n",
      "Concept 44:\n",
      "index table con\n",
      "rep\n",
      "table con\n",
      "table con dm\n",
      "ci\n",
      "dm uw rep\n",
      "event marked\n",
      "event marked unusable\n",
      "rep vod\n",
      "uw rep\n",
      " \n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "for i, comp in enumerate(lsa.components_): \n",
    "    termsInComp = zip (terms,comp)\n",
    "    sortedTerms =  sorted(termsInComp, key=lambda x: x[1], reverse=True) [:10]\n",
    "    print(\"Concept %d:\" % i)\n",
    "    for term in sortedTerms:\n",
    "        print(term[0])\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we need to see how can we extract other two matrix for our benefit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
