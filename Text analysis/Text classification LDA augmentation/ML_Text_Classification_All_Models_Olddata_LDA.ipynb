{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 63262 entries, 0 to 63261\n",
      "Data columns (total 3 columns):\n",
      "Title         63261 non-null object\n",
      "Security      63262 non-null object\n",
      "SourceLink    63262 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "with open('Manual WorkItems alltypes Security.csv', encoding='ascii', errors='ignore') as infile:\n",
    "    dataset1 = pd.read_csv(infile,names = ['Title', 'Security', 'SourceLink'])\n",
    "with open('Manual WorkItems alltypes nonSecurity.csv', encoding='ascii', errors='ignore') as infile:\n",
    "    dataset2 = pd.read_csv(infile,names = ['Title', 'Security', 'SourceLink'])\n",
    "    \n",
    "dataset1 = dataset1.sample(frac = 0.45, random_state= 123).reset_index(drop = True)\n",
    "dataset1.info()\n",
    "\n",
    "dataset1['IsSecured'] = 1\n",
    "dataset2['IsSecured'] = 0\n",
    "\n",
    "dataset = pd.concat([dataset1, dataset2]).reset_index(drop = True)\n",
    "dataset = dataset.sample(frac = 1).reset_index(drop = True)\n",
    "\n",
    "dataset.dropna(axis=0, how='any', inplace = True)\n",
    "dataset=dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "my_stopwords = stopwords.words('english')\n",
    "#type(my_stopwords),my_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patsy import dmatrices\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "def splitall(path):\n",
    "    allparts = []\n",
    "    while 1:\n",
    "        parts = os.path.split(path)\n",
    "        if parts[0] == path:  # sentinel for absolute paths\n",
    "            allparts.insert(0, parts[0])\n",
    "            break\n",
    "        elif parts[1] == path: # sentinel for relative paths\n",
    "            allparts.insert(0, parts[1])\n",
    "            break\n",
    "        else:\n",
    "            path = parts[0]\n",
    "            allparts.insert(0, parts[1])\n",
    "    return \" \".join(allparts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will now apply the splitall function on the dataset.\n",
    "dataset['Parsed Title'] = dataset['Title'].apply(splitall)\n",
    "#dataset.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "def clean_text(text):\n",
    "    text = \"\".join([char if char.isalpha() else \" \" for char in text.lower()]).split()\n",
    "    #text = [ps.stem(word) for word in text]\n",
    "    #text = \" \".join([word for word in text if (word not in my_stopwords and len(word) > 2)])\n",
    "    text = \" \".join([word for word in text if (len(word) > 2)])\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.1 s\n"
     ]
    }
   ],
   "source": [
    "%time dataset['Clean Title'] = dataset['Parsed Title'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer,CountVectorizer\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "X, y = dataset['Clean Title'], dataset['IsSecured']\n",
    "cvectorizer = CountVectorizer(min_df=20, stop_words='english')\n",
    "#tv = TfidfVectorizer(min_df=0.001, max_df= 1.0, use_idf=True,ngram_range=(1,3))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "cvz = cvectorizer.fit_transform(X_train)#.toarray()\n",
    "X_val = cvectorizer.transform(X_val)#.toarray()\n",
    "vocab = cvectorizer.get_feature_names()\n",
    "print(len(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<97646x3904 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 716343 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24412, 3904), (97646,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape,X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 97646\n",
      "INFO:lda:vocab_size: 3904\n",
      "INFO:lda:n_words: 763196\n",
      "INFO:lda:n_topics: 33\n",
      "INFO:lda:n_iter: 500\n",
      "WARNING:lda:all zero row in document-term matrix found\n",
      "C:\\Users\\inpganavar\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\lda\\utils.py:55: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if sparse and not np.issubdtype(doc_word.dtype, int):\n",
      "INFO:lda:<0> log likelihood: -9084161\n",
      "INFO:lda:<10> log likelihood: -6398433\n",
      "INFO:lda:<20> log likelihood: -5857462\n",
      "INFO:lda:<30> log likelihood: -5710124\n",
      "INFO:lda:<40> log likelihood: -5641363\n",
      "INFO:lda:<50> log likelihood: -5604766\n",
      "INFO:lda:<60> log likelihood: -5580474\n",
      "INFO:lda:<70> log likelihood: -5562223\n",
      "INFO:lda:<80> log likelihood: -5549584\n",
      "INFO:lda:<90> log likelihood: -5540420\n",
      "INFO:lda:<100> log likelihood: -5532571\n",
      "INFO:lda:<110> log likelihood: -5525362\n",
      "INFO:lda:<120> log likelihood: -5517430\n",
      "INFO:lda:<130> log likelihood: -5511407\n",
      "INFO:lda:<140> log likelihood: -5508181\n",
      "INFO:lda:<150> log likelihood: -5503753\n",
      "INFO:lda:<160> log likelihood: -5501796\n",
      "INFO:lda:<170> log likelihood: -5501270\n",
      "INFO:lda:<180> log likelihood: -5497581\n",
      "INFO:lda:<190> log likelihood: -5495374\n",
      "INFO:lda:<200> log likelihood: -5493929\n",
      "INFO:lda:<210> log likelihood: -5493773\n",
      "INFO:lda:<220> log likelihood: -5493451\n",
      "INFO:lda:<230> log likelihood: -5491866\n",
      "INFO:lda:<240> log likelihood: -5493030\n",
      "INFO:lda:<250> log likelihood: -5490574\n",
      "INFO:lda:<260> log likelihood: -5489482\n",
      "INFO:lda:<270> log likelihood: -5488793\n",
      "INFO:lda:<280> log likelihood: -5488503\n",
      "INFO:lda:<290> log likelihood: -5487213\n",
      "INFO:lda:<300> log likelihood: -5487414\n",
      "INFO:lda:<310> log likelihood: -5488453\n",
      "INFO:lda:<320> log likelihood: -5487986\n",
      "INFO:lda:<330> log likelihood: -5488520\n",
      "INFO:lda:<340> log likelihood: -5486870\n",
      "INFO:lda:<350> log likelihood: -5486675\n",
      "INFO:lda:<360> log likelihood: -5486695\n",
      "INFO:lda:<370> log likelihood: -5485078\n",
      "INFO:lda:<380> log likelihood: -5486524\n",
      "INFO:lda:<390> log likelihood: -5486511\n",
      "INFO:lda:<400> log likelihood: -5486277\n",
      "INFO:lda:<410> log likelihood: -5486932\n",
      "INFO:lda:<420> log likelihood: -5486231\n",
      "INFO:lda:<430> log likelihood: -5485386\n",
      "INFO:lda:<440> log likelihood: -5485703\n",
      "INFO:lda:<450> log likelihood: -5487086\n",
      "INFO:lda:<460> log likelihood: -5484820\n",
      "INFO:lda:<470> log likelihood: -5484760\n",
      "INFO:lda:<480> log likelihood: -5484041\n",
      "INFO:lda:<490> log likelihood: -5486099\n",
      "INFO:lda:<499> log likelihood: -5485117\n"
     ]
    }
   ],
   "source": [
    "import lda\n",
    "\n",
    "# train an LDA model\n",
    "lda_model = lda.LDA(n_topics=33, n_iter=500)\n",
    "X_topics = lda_model.fit_transform(cvz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "threshold = 0.5\n",
    "_idx = np.amax(X_topics, axis=1) > threshold  # idx of doc that above the threshold\n",
    "X_topics = X_topics[_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 28125 samples in 0.237s...\n",
      "[t-SNE] Computed neighbors for 28125 samples in 55.892s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 7000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 8000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 9000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 10000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 11000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 12000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 13000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 14000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 15000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 16000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 17000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 18000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 19000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 20000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 21000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 22000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 23000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 24000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 25000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 26000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 27000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 28000 / 28125\n",
      "[t-SNE] Computed conditional probabilities for sample 28125 / 28125\n",
      "[t-SNE] Mean sigma: 0.000000\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 68.227112\n",
      "[t-SNE] Error after 1000 iterations: 1.047794\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# a t-SNE model\n",
    "# angle value close to 1 means sacrificing accuracy for speed\n",
    "# pca initializtion usually leads to better results \n",
    "tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
    "\n",
    "# 20-D -> 2-D\n",
    "tsne_lda = tsne_model.fit_transform(X_topics)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import bokeh.plotting as bp\n",
    "from bokeh.plotting import save\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "n_top_words = 5 # number of keywords we show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lda_keys = []\n",
    "for i in range(X_topics.shape[0]):\n",
    "    _lda_keys +=  X_topics[i].argmax(),\n",
    "\n",
    "topic_summaries = []\n",
    "topic_word = lda_model.topic_word_  # all topic words\n",
    "vocab = cvectorizer.get_feature_names()\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words + 1):-1] # get!\n",
    "    topic_summaries.append(' '.join(topic_words)) # append!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = np.array([\n",
    "    \"#1f77b4\", \"#aec7e8\", \"#ff7f0e\", \"#ffbb78\", \"#2ca02c\",\n",
    "    \"#98df8a\", \"#d62728\", \"#ff9896\", \"#9467bd\", \"#c5b0d5\",\n",
    "    \"#8c564b\", \"#c49c94\", \"#e377c2\", \"#f7b6d2\", \"#7f7f7f\",\n",
    "    \"#c7c7c7\", \"#bcbd22\", \"#dbdb8d\", \"#17becf\", \"#9edae5\",\n",
    "    \"#1f7874\", \"#aec777\", \"#fffeee\", \"#ffbbbb\", \"#2caaac\",\n",
    "    \"#98dfaa\", \"#d66666\", \"#ff9996\", \"#9499bd\", \"#c55445\",\n",
    "    \"#8c5467\", \"#c49ccc\", \"#e33332\", \"#f77dd2\", \"#7ffeef\",\n",
    "    \"#c7c9d9\", \"#bc4321\", \"#dbbbed\", \"#17bbef\", \"#9eeea5\",\n",
    "    \"#1fc7bb\", \"#ae8888\", \"#ffebbe\", \"#aebf18\", \"#2caaac\",\n",
    "    \"#981f2a\", \"#d66ee7\", \"#ff9996\", \"#91eebd\", \"#c555d5\",\n",
    "    \"#8c321b\", \"#c4444a\", \"#eeefff\", \"#fbbdd2\", \"#77777f\",\n",
    "    \"#c7b7b7\", \"#bc1222\", \"#dbae8d\", \"#17cccf\", \"#9eddd5\",\n",
    "    \"#c7f7f7\", \"#bace22\", \"#db818d\", \"#17bfff\", \"#9eaaa5\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: table;\"><div style=\"display: table-row;\"><div style=\"display: table-cell;\"><b title=\"bokeh.models.renderers.GlyphRenderer\">GlyphRenderer</b>(</div><div style=\"display: table-cell;\">id&nbsp;=&nbsp;'1f54c4c2-5690-4e9b-bf47-1f43c0b3d896', <span id=\"e865bff5-1799-449c-8b18-e39fd65d7755\" style=\"cursor: pointer;\">&hellip;)</span></div></div><div class=\"632f57d8-e435-4a0c-a49d-9f12c8b260df\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">data_source&nbsp;=&nbsp;ColumnDataSource(id='f9ad6c9d-656c-4f2d-86f2-399c107b63fb', ...),</div></div><div class=\"632f57d8-e435-4a0c-a49d-9f12c8b260df\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">glyph&nbsp;=&nbsp;Circle(id='7681fe4a-3e38-4792-afc1-9ec11ba22e3d', ...),</div></div><div class=\"632f57d8-e435-4a0c-a49d-9f12c8b260df\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">hover_glyph&nbsp;=&nbsp;None,</div></div><div class=\"632f57d8-e435-4a0c-a49d-9f12c8b260df\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_event_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"632f57d8-e435-4a0c-a49d-9f12c8b260df\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_property_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"632f57d8-e435-4a0c-a49d-9f12c8b260df\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">level&nbsp;=&nbsp;'glyph',</div></div><div class=\"632f57d8-e435-4a0c-a49d-9f12c8b260df\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">muted&nbsp;=&nbsp;False,</div></div><div class=\"632f57d8-e435-4a0c-a49d-9f12c8b260df\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">muted_glyph&nbsp;=&nbsp;None,</div></div><div class=\"632f57d8-e435-4a0c-a49d-9f12c8b260df\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">name&nbsp;=&nbsp;None,</div></div><div class=\"632f57d8-e435-4a0c-a49d-9f12c8b260df\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">nonselection_glyph&nbsp;=&nbsp;Circle(id='aab6426a-0786-4a03-b002-6c64c785d086', ...),</div></div><div class=\"632f57d8-e435-4a0c-a49d-9f12c8b260df\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">selection_glyph&nbsp;=&nbsp;None,</div></div><div class=\"632f57d8-e435-4a0c-a49d-9f12c8b260df\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">subscribed_events&nbsp;=&nbsp;[],</div></div><div class=\"632f57d8-e435-4a0c-a49d-9f12c8b260df\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">tags&nbsp;=&nbsp;[],</div></div><div class=\"632f57d8-e435-4a0c-a49d-9f12c8b260df\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">view&nbsp;=&nbsp;CDSView(id='c236162f-8fa8-4359-9f9a-c42b5cedd73e', ...),</div></div><div class=\"632f57d8-e435-4a0c-a49d-9f12c8b260df\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">visible&nbsp;=&nbsp;True,</div></div><div class=\"632f57d8-e435-4a0c-a49d-9f12c8b260df\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">x_range_name&nbsp;=&nbsp;'default',</div></div><div class=\"632f57d8-e435-4a0c-a49d-9f12c8b260df\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">y_range_name&nbsp;=&nbsp;'default')</div></div></div>\n",
       "<script>\n",
       "(function() {\n",
       "  var expanded = false;\n",
       "  var ellipsis = document.getElementById(\"e865bff5-1799-449c-8b18-e39fd65d7755\");\n",
       "  ellipsis.addEventListener(\"click\", function() {\n",
       "    var rows = document.getElementsByClassName(\"632f57d8-e435-4a0c-a49d-9f12c8b260df\");\n",
       "    for (var i = 0; i < rows.length; i++) {\n",
       "      var el = rows[i];\n",
       "      el.style.display = expanded ? \"none\" : \"table-row\";\n",
       "    }\n",
       "    ellipsis.innerHTML = expanded ? \"&hellip;)\" : \"&lsaquo;&lsaquo;&lsaquo;\";\n",
       "    expanded = !expanded;\n",
       "  });\n",
       "})();\n",
       "</script>\n"
      ],
      "text/plain": [
       "GlyphRenderer(id='1f54c4c2-5690-4e9b-bf47-1f43c0b3d896', ...)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = '33 groups LDA viz'\n",
    "num_example = len(X_topics)\n",
    "\n",
    "plot_lda = bp.figure(plot_width=1400, plot_height=1100,\n",
    "                     title=title,\n",
    "                     tools=\"pan,wheel_zoom,box_zoom,reset,hover,previewsave\",\n",
    "                     x_axis_type=None, y_axis_type=None, min_border=1)\n",
    "\n",
    "plot_lda.circle(x=tsne_lda[:,0], y=tsne_lda[:, 1],\n",
    "                 color=colormap[_lda_keys][:num_example]\n",
    "                 )\n",
    "\n",
    "#source = ColumnDataSource(data=dict(x= tsne_lda[:, 0], y=tsne_lda[:, 1]))\n",
    "#plot_lda.circe(x='x', y='x',source=source)\n",
    "#plot_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\inpganavar\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\bokeh\\io\\saving.py:125: UserWarning: save() called but no resources were supplied and output_file(...) was never called, defaulting to resources.CDN\n",
      "  warn(\"save() called but no resources were supplied and output_file(...) was never called, defaulting to resources.CDN\")\n",
      "C:\\Users\\inpganavar\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\bokeh\\io\\saving.py:138: UserWarning: save() called but no title was supplied and output_file(...) was never called, using default title 'Bokeh Plot'\n",
      "  warn(\"save() called but no title was supplied and output_file(...) was never called, using default title 'Bokeh Plot'\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\inpganavar\\\\Desktop\\\\MS\\\\63 groups LDA viz.html'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly choose a news (within a topic) coordinate as the crucial words coordinate\n",
    "topic_coord = np.empty((X_topics.shape[1], 2)) * np.nan\n",
    "for topic_num in _lda_keys:\n",
    "    if not np.isnan(topic_coord).any():\n",
    "        break\n",
    "    topic_coord[topic_num] = tsne_lda[_lda_keys.index(topic_num)]\n",
    "\n",
    "# plot crucial words\n",
    "for i in range(X_topics.shape[1]):\n",
    "    plot_lda.text(topic_coord[i, 0], topic_coord[i, 1], [topic_summaries[i]])\n",
    "\n",
    "# hover tools\n",
    "hover = plot_lda.select(dict(type=HoverTool))\n",
    "hover.tooltips = {\"content\": \"@content - topic: @topic_key\"}\n",
    "\n",
    "# save the plot\n",
    "save(plot_lda, '{}.html'.format(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
